# ğŸ§© NeetCode Practice Framework

<!-- 
SEO: leetcode, algorithm, data structure, coding interview, FAANG, competitive programming, neetcode, 
     blind 75, python, mind map, pattern, dynamic programming, interview preparation, knowledge graph
AEO/GEO: A scalable Python framework with knowledge graph-driven learning, AI-powered mind maps,
         industrial-strength testing, and pattern-based learning for algorithm mastery.
-->

[![GitHub stars](https://img.shields.io/github/stars/lufftw/neetcode?style=for-the-badge&logo=github&color=gold)](https://github.com/lufftw/neetcode/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/lufftw/neetcode?style=for-the-badge&logo=github&color=silver)](https://github.com/lufftw/neetcode/network)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](https://github.com/lufftw/neetcode/blob/main/LICENSE)

[![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/GPT--Powered-412991?style=flat-square&logo=openai&logoColor=white)](https://openai.com/)
[![VS Code](https://img.shields.io/badge/VS%20Code-007ACC?style=flat-square&logo=visual-studio-code&logoColor=white)](https://code.visualstudio.com/)
[![pytest](https://img.shields.io/badge/150%2B%20Tests-0A9EDC?style=flat-square&logo=pytest&logoColor=white)](https://github.com/lufftw/neetcode/tree/main/.dev/tests)
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen?style=flat-square&logo=git&logoColor=white)](https://github.com/lufftw/neetcode/pulls)

---

**Solve. Forget. Repeat. Letâ€™s Fix That.**

### ğŸ¯ Build Algorithmic Intuition

**NeetCode is a scalable Python practice framework for algorithm learning and interview prep â€” build intuition and pattern recognition, turn ideas into clean implementations, and accumulate *verifiable evidence* (tests, stress cases, benchmarks, complexity checks) so your progress is real, repeatable, and interview-ready.**

- **Learn the transferable skills**: modeling, state/invariants, edge cases, complexity awareness, and reusable solution templates.
- **Interview-ready practice**: time-boxed workflows, explain-while-coding, fewer â€œsmall bugsâ€, stronger trade-off discussions.
- **Prove correctness & robustness**: static + seeded random + edge-case stress tests, custom judges, failure reproduction.
- **Measure and compare**: benchmark multiple implementations and empirically estimate complexity.
- **See the big picture**: ontology + AI mind maps reveal pattern relationships and learning paths.

[ğŸ“š Docs](https://lufftw.github.io/neetcode/) â€¢ [ğŸ§ª Testing & Validation](docs/runner/README.md) â€¢ [ğŸ¤– AI Mind Maps](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-agent-evolved-en.html) â€¢ [ğŸ§  Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“ Patterns](docs/patterns/README.md)

[English](https://lufftw.github.io/neetcode/) | [ç¹é«”ä¸­æ–‡](https://lufftw.github.io/neetcode/index_zh-TW/)

---

**Topics:** `knowledge-graph` `ai-powered` `mind-map` `pattern-recognition` `leetcode` `neetcode-150` `blind-75` `stress-testing` `algorithm-engineering` `performance-benchmarking` `data-driven-testing` `random-test-generation` `judge-function` `algorithm-debugging` `competitive-programming` `python` `vscode-integration` `test-automation` `pre-commit` `local-automation` `coding-interview`

---

## ğŸ’ Core Philosophy

> **"Algorithm mastery is not about memorizing 300 solutions â€” it's about internalizing 15 fundamental patterns and knowing precisely when to apply each one."**

This framework embodies three transformative principles:

### ğŸ§¬ Knowledge Graph Architecture

Traditional LeetCode practice treats problems as isolated units. We built an **interconnected ontology system** where:

- **API Kernels** define reusable algorithmic primitives (`SubstringSlidingWindow`, `GridBFS`, `BacktrackExplore`)
- **Patterns** compose kernels into higher-level strategies
- **Problem Families** reveal structural relationships across 300+ problems
- **AI Synthesis** discovers non-obvious connections humans miss

*This is how experts think â€” in abstractions, not in solutions.*

### âš™ï¸ Production-Grade Validation

Your solution passes LeetCode's tests. But is it *correct*? Is it *optimal*? We provide **ICPC/Codeforces-caliber testing infrastructure**:

| Capability | What It Proves |
|:-----------|:---------------|
| ğŸ² **Seeded Random Generation** | Your code handles cases you never imagined |
| âš–ï¸ **Custom Judge Functions** | Multiple valid answers are all accepted |
| ğŸ“Š **Multi-Solution Benchmarking** | Which approach is *actually* faster |
| ğŸ“ˆ **Empirical Complexity Estimation** | Your O(n log n) claim is verified |

*This is how Google engineers validate â€” through exhaustive, reproducible testing.*

### ğŸ¤– AI-Augmented Understanding

We don't just store knowledge â€” we **synthesize insight**:

- AI analyzes the entire ontology to generate **creative, interconnected mind maps**
- Multi-perspective synthesis: Architect Ã— Professor Ã— Engineer Ã— Competitor
- Problems link to **GitHub solutions** (when available) or **LeetCode** (fallback)

*This is how the next generation learns â€” with AI as a thinking partner.*

---

## ğŸŒŸ What Sets Us Apart

> ğŸ’¡ **"Great algorithmic skill isnâ€™t about finding an answer â€” itâ€™s about building systems that make correctness, performance, and learning provable."**

| ğŸ“¦ Other LeetCode Repos | ğŸš€ NeetCode |
|:------------------------|:------------|
| âŒ Binary feedback ("Accepted / Wrong") | ğŸ§© **Evidence-driven loop**: golden tests + seeded fuzz + edge-case stress |
| âŒ Single solution, unknown behavior | ğŸ§© **Multiple implementations** + side-by-side benchmarks |
| âŒ Flat, tag-only pattern labels | ğŸ§© **Interactive mind maps** linking problems, patterns, and kernels |
| âŒ No AI-assisted discovery | ğŸ¤– **AI-powered connections** across related problems, patterns, and approaches |
| âŒ Patterns limited to static notes | ğŸ§  **Dual learning paths per pattern:** intuition-driven explanations for mental models, plus reusable templates for interviews and fast recall |
| âŒ Manual runs, inconsistent environments | âš™ï¸ **Deterministic CLI + VS Code tasks/debug** |
| âŒ "Accepted" without proof | ğŸ” **Invariant-aware solutions** + explicit failure modes |
| âŒ Ad-hoc edge cases | ğŸ§  **Systematic edge-case taxonomy** |
| âŒ Solution-first memorization | ğŸ§  **Pattern-first transfer learning** (interview-ready) |
| âŒ Big-O as documentation only | ğŸ“Š **Measured time / space trade-offs** under identical inputs |
| âŒ Complexity claimed, not verified | ğŸ“Š **Complexity + empirical benchmarks** under identical conditions |
| âŒ Results hard to reproduce | âš™ï¸ **Deterministic, reproducible experiments** |
| âŒ Flat problem collection | ğŸ§© **Skill & pattern progression tracking** |
| âŒ Silent failures | ğŸ” **Auto-captured counterexamples** for debugging |
| âŒ Human-written notes only | ğŸ¤– **AI-augmented reasoning layer** (summaries, maps, kernels) |

<sub>

**Legend â€” Capability Categories**  
ğŸ§  Learning & reasoning layer  
ğŸ§© System architecture & structure  
âš™ï¸ Execution & tooling infrastructure  
ğŸ“Š Empirical measurement & benchmarks  
ğŸ” Debugging & correctness analysis  
ğŸ¤– AI-assisted augmentation  

</sub>


### ğŸ§  The Knowledge Graph Advantage

Most people practice algorithms in isolation. We built an **interconnected knowledge system**:

| Mind Map | Description | Link |
|:---------|:------------|:----:|
| ğŸ¤– **AI Ontology Analysis (Evolved)** | Generated via a multi-agent pipeline | [ğŸ”— EN](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-agent-evolved-en.html) Â· [ğŸ”— ä¸­æ–‡](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-agent-evolved-zh-tw.html) |
| ğŸ¤– **AI Ontology Analysis** | AI-powered deep pattern synthesis | [ğŸ”— EN](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-ai-en.html) Â· [ğŸ”— ä¸­æ–‡](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-ai-zh-tw.html) |
| ğŸ“ **Pattern Hierarchy** | API kernels â†’ patterns â†’ solutions | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/pattern-hierarchy.html) |
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family Derivation** | Base templates â†’ derived variants | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/family-derivation.html) |
| âš¡ **Algorithm Usage** | Know which algorithm applies where | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/algorithm-usage.html) |
| ğŸ¢ **Company Coverage** | Target preparation for specific companies | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/company-coverage.html) |
| ğŸ—ºï¸ **Learning Roadmaps** | NeetCode 150, Blind 75, etc. | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/roadmap-paths.html) |

**[â†’ Explore 10+ Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

### âš™ï¸ Industrial-Strength Testing

Built on principles from **Codeforces, ICPC, and Google's engineering practices**:

| Capability | What It Does | Why It Matters |
|:-----------|:-------------|:---------------|
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility | Find edge cases you never imagined |
| âš–ï¸ **Custom Judge Functions** | ICPC-style validation logic | Multiple correct answers? No problem |
| ğŸ“Š **Multi-Solution Benchmark** | Compare N approaches automatically | Know which is *actually* faster |
| ğŸ“ˆ **Complexity Estimation** | Empirical Big-O analysis | Verify your theoretical claims |
| ğŸ”§ **VS Code Integration** | One-click debug, tasks, shortcuts | Debug algorithms like real software |

---

## ğŸ“‘ Table of Contents

- [What Sets Us Apart](#-what-sets-us-apart)
- [Why This Framework?](#-why-this-framework)
- [Quick Start](#-quick-start)
- [Key Features](#-key-features)
- [Interactive Mind Maps](#-interactive-mind-maps)
- [AI Mind Map Generation](#-ai-mind-map-generation)
- [Pattern Documentation](#-pattern-documentation)
- [Usage Guide](#-usage-guide)
- [Advanced Features](#-advanced-features)
- [Project Architecture](#-project-architecture)
- [FAQ](#-frequently-asked-questions)
- [For Contributors](#-for-contributors)
- [License](#-license)

---

## â­ Why This Framework?

### The Problem with Traditional Practice

You solve a problem on LeetCode. It passes. But do you *really* know if your solution is correct? What about:

- That edge case with empty input you didn't test?
- The subtle off-by-one error that only appears with large N?
- Whether your O(n log n) claim is actually true?

**Traditional practice leaves these questions unanswered.** This framework answers them definitively.

### What Makes Us Different

| Capability | This Framework | Typical Repos |
|:-----------|:-------------:|:-------------:|
| **Reproducible Random Tests** | âœ… Seeded generators | âŒ Manual only |
| **Custom Judge Functions** | âœ… ICPC/Codeforces style | âŒ String match |
| **Multi-Solution Benchmarking** | âœ… Compare N approaches | âŒ Single solution |
| **VS Code Integration** | âœ… Tasks, Debug, Shortcuts | âŒ CLI only |
| **Stress Testing** | âœ… Generate 1000+ cases | âŒ Limited |
| **Complexity Estimation** | âœ… Automatic Big-O | âŒ None |

### Built For Excellence

| Audience | How We Help |
|:---------|:------------|
| ğŸ† **Competitive Programmers** | Train like Codeforces grandmasters â€” stress test until you break your code, then fix it |
| ğŸ’¼ **FAANG Engineers** | Build interview confidence by proving your solutions work, not just hoping they do |
| ğŸ“ **CS Students** | Learn algorithms the right way â€” through experimentation, not memorization |
| ğŸ‘¨â€ğŸ« **Educators** | Give students industrial-grade tools to validate their understanding |
| ğŸ”¬ **Researchers** | Benchmark algorithm variants at scale with reproducible methodology |

---

## ğŸš€ Quick Start

### 1. Setup Environment

#### Windows (PowerShell)

```powershell
# Clone and navigate to project
cd C:\path\to\neetcode

# Install Python 3.11 (if needed)
py install 3.11

# Create and activate virtual environment
py -3.11 -m venv leetcode
leetcode\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### Linux / macOS

```bash
# Using pyenv (recommended)
pyenv install 3.11
pyenv local 3.11

# Create and activate virtual environment
python -m venv leetcode
source leetcode/bin/activate

# Install dependencies
pip install -r requirements.txt

# Make scripts executable
chmod +x scripts/run_tests.sh scripts/run_case.sh scripts/new_problem.sh
```

### 2. Create Your First Problem

```bash
# Windows
scripts\new_problem.bat 1
scripts\new_problem.bat 1 --with-tests

# Linux/macOS
./scripts/new_problem.sh 1
./scripts/new_problem.sh 1 --with-tests
```

This creates:
- `solutions/0001_two_sum.py` â€” Your solution file
- `tests/0001_two_sum_1.in/.out` â€” Example-based tests (when `--with-tests`)

**New options:**

```bash
# New flags
scripts\new_problem.bat 1 --solve-mode tiered  # Use tiered codec generation
scripts\new_problem.bat 1 --codec-mode import  # Use import mode (default)
scripts\new_problem.bat 1 --codec-mode inline  # Embed codec inline

# Auto-detect (no need to specify --solve-mode)
scripts\new_problem.bat 104  # Tree problems â†’ auto tiered codec + solve()
scripts\new_problem.bat 142  # Linked list cycle problems â†’ auto tiered codec + solve()
```

**More CodeGen commands (optional):**

```bash
# Check whether your existing tests match LeetCode examples
python -m packages.codegen check 1
python -m packages.codegen check --all --limit 10

# Migrate tests to canonical JSON-literal format (preview first)
python -m packages.codegen migrate 1 --dry-run
python -m packages.codegen migrate --all --dry-run
```

> ğŸ“– Full reference: [`docs/packages/codegen/README.md`](docs/packages/codegen/README.md)

### 3. Run Tests

```bash
# Windows
scripts\run_tests.bat 0001_two_sum

# Linux/macOS
./scripts/run_tests.sh 0001_two_sum
```

### 4. Debug in VS Code

1. Open any solution file in `solutions/`
2. Press `F5` to debug with test case #1
3. Or press `Ctrl+Shift+B` to run all tests

**That's it!** You're ready to solve problems. ğŸ‰

---

## âœ¨ Key Features

| Feature | Description |
|:--------|:------------|
| ğŸ§ª **Testing & Validation Engine** | â­ **Core Feature** â€” Automated testing, benchmarking, random test generation, complexity estimation. See [Testing & Validation Guide](docs/runner/README.md) |
| ğŸ§° **One-Command Scaffolding (CodeGen)** | Create a full problem scaffold from a LeetCode ID: `solutions/*.py` + optional example tests (`tests/*.in/.out`) + auto `solve()` generation. For problems with **non-trivial input/output adapters** (e.g. trees, linked lists, cycles), CodeGen can **auto-detect** and generate a tiered codec-based `solve()` (`--solve-mode tiered`). See [CodeGen Docs](docs/packages/codegen/README.md). |
| ğŸ§¾ **Canonical Test Contract + Migration** | Test files use **JSON literal, one value per line** for diff-friendly, machine-stable I/O. Includes `check` (consistency vs LeetCode examples) and `migrate` (auto-convert existing tests) workflows. See [`docs/contracts/test-file-format.md`](docs/contracts/test-file-format.md). |
| ğŸ§  **Memory Profiling (Optional)** | Runner can show **memory traces and rankings** across methods (`--memory-trace`, `--trace-compare`, `--memory-per-case`) when optional deps are installed. See [Runner Spec](docs/runner/README.md). |
| ğŸ¤– **AI Ontology Analysis** | AI-powered knowledge graph synthesis â€” discover pattern relationships humans miss |
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility, stress test with 1000+ cases, auto-save failing cases |
| âš–ï¸ **Custom Judge Functions** | Validate multiple correct answers, ICPC-style validation, works without expected output |
| ğŸ“Š **Performance Analysis** | Benchmark multiple solutions, automatic time complexity estimation, side-by-side comparison |
| ğŸ”§ **VS Code Integration** | One-click test execution, integrated debugging, custom tasks and shortcuts |
| ğŸ§  **Interactive Mind Maps** | Visualize algorithm patterns, track learning progress â€” [Explore â†’](https://lufftw.github.io/neetcode/mindmaps/) |

---

## ğŸ§  Interactive Mind Maps

Visualize algorithm patterns, problem relationships, and learning paths:

### ğŸ¤– AI-Powered Ontology Analysis (NEW!)

> **"Let AI synthesize what takes humans years to internalize."**

Our **AI Ontology Analyzer** processes the entire knowledge graph â€” API Kernels, Patterns, Algorithms, Data Structures, Problem Families â€” and generates **creative, interconnected mind maps** that reveal insights human-curated lists miss.

| Language | Description | Links |
|:---------|:------------|:------|
| **English (Evolved)** | Generated via a multi-agent pipeline | [Static](docs/mindmaps/neetcode-ontology-agent-evolved-en.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-agent-evolved-en.html) |
| **ç¹é«”ä¸­æ–‡ (Evolved)** | ç”±å¤šä»£ç†ï¼ˆmulti-agentï¼‰æµç¨‹ç”¢ç”Ÿ | [Static](docs/mindmaps/neetcode-ontology-agent-evolved-zh-tw.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-agent-evolved-zh-tw.html) |
| **English** | AI-synthesized pattern relationships | [Static](docs/mindmaps/neetcode-ontology-ai-en.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-ai-en.html) |
| **ç¹é«”ä¸­æ–‡** | AI æ™ºèƒ½åˆ†ææ¨¡å¼é—œè¯ | [Static](docs/mindmaps/neetcode-ontology-ai-zh-tw.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode-ontology-ai-zh-tw.html) |

**What makes it special:**
- ğŸ§¬ **Deep Pattern Synthesis** â€” AI identifies non-obvious connections between patterns
- ğŸ¯ **Smart Linking** â€” Problems link to GitHub solutions (when available) or LeetCode
- ğŸŒ **Multi-language** â€” Generate in English and ç¹é«”ä¸­æ–‡
- â™»ï¸ **Regeneratable** â€” Run `python tools/mindmaps/generate_mindmaps_ai.py` to create fresh insights

---

### ğŸ“š Curated Mind Maps

| Mind Map | Description | Links |
|:---------|:------------|:------|
| ğŸ“ **Pattern Hierarchy** | API Kernels â†’ Patterns â†’ Problems | [Static](docs/mindmaps/pattern-hierarchy.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/pattern-hierarchy.html) |
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family Derivation** | Base templates â†’ Derived variants | [Static](docs/mindmaps/family-derivation.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/family-derivation.html) |
| âš¡ **Algorithm Usage** | Problems by algorithm | [Static](docs/mindmaps/algorithm-usage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/algorithm-usage.html) |
| ğŸ—ï¸ **Data Structure Usage** | Problems by data structure | [Static](docs/mindmaps/data-structure.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/data-structure.html) |
| ğŸ¢ **Company Coverage** | Company-specific problems | [Static](docs/mindmaps/company-coverage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/company-coverage.html) |
| ğŸ—ºï¸ **Learning Roadmaps** | NeetCode 150, Blind 75, etc. | [Static](docs/mindmaps/roadmap-paths.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/roadmap-paths.html) |
| ğŸ”— **Problem Relations** | Related problems network | [Static](docs/mindmaps/problem-relations.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/problem-relations.html) |
| ğŸ”€ **Solution Variants** | Multiple approaches | [Static](docs/mindmaps/solution-variants.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/solution-variants.html) |
| ğŸ“Š **Difficulty Ã— Topics** | Topics by difficulty | [Static](docs/mindmaps/difficulty-topics.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/difficulty-topics.html) |

ğŸ‘‰ **[View All Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

---

## ğŸ¤– AI Mind Map Generation

> **"Let AI synthesize what takes humans years to internalize."**

### Two Generation Modes

| Mode | Description | Quick Start |
|:-----|:------------|:------------|
| **ğŸ¤– Evolved Agent** | Multi-expert refinement with consensus voting | `cd tools/mindmaps/ai-markmap-agent && python main.py` |
| **ğŸ¤– Basic AI** | Single-pass synthesis from knowledge graph | `python tools/mindmaps/generate_mindmaps_ai.py` |

### Key Features

- ğŸ§¬ **Multi-Expert Synthesis** â€” Architect + Professor + Engineer perspectives
- ğŸ¯ **Smart Linking** â€” GitHub solution (if exists) â†’ LeetCode fallback
- ğŸŒ **Multi-language** â€” EN / ç¹é«”ä¸­æ–‡
- â™»ï¸ **Regeneratable** â€” Version history with auto-increment

### Output Files

| Type | Output Path |
|:-----|:------------|
| **Evolved** | `docs/mindmaps/neetcode_ontology_agent_evolved_{lang}.md` |
| **Basic** | `docs/mindmaps/neetcode_ontology_ai_{lang}.md` |
| **HTML** | `docs/pages/mindmaps/*.html` |

> ğŸ“– **Evolved Agent**: See [`tools/mindmaps/ai-markmap-agent/README.md`](docs/tools/mindmaps/ai-markmap-agent/README.md) for architecture, expert roles, and configuration.
>
> ğŸ“– **Basic AI**: See [`tools/README.md`](docs/tools/README.md) for configuration options.

---

## ğŸ“ Pattern Documentation

> **"Don't memorize 200 problems. Master 10 patterns."**

Each pattern provides **two learning paths**:

| Path | Purpose | Best For |
|:-----|:--------|:---------|
| ğŸ’¡ **Intuition** | Understand the "why" through stories and visual explanations | First-time learners, building mental models |
| ğŸ› ï¸ **Templates** | Production-ready implementations with problem-specific variations | Interview prep, quick reference |

| API Kernel | Learning Resources | Problems |
|:-----------|:-------------------|:---------|
| `SubstringSlidingWindow` | ğŸ’¡ [Intuition](docs/patterns/sliding_window/intuition.md) Â· ğŸ› ï¸ [Templates](docs/patterns/sliding_window/templates.md) | LeetCode 3, 76, 159, 209, 340, 438, 567 |
| `TwoPointersTraversal` | ğŸ’¡ [Intuition](docs/patterns/two_pointers/intuition.md) Â· ğŸ› ï¸ [Templates](docs/patterns/two_pointers/templates.md) | LeetCode 1, 11, 15, 16, 21, 26, 27, 75, 88, 125, 141, 142, 167, 202, 283, 680, 876 |
| `BacktrackingExploration` | ğŸ’¡ [Intuition](docs/patterns/backtracking_exploration/intuition.md) Â· ğŸ› ï¸ [Templates](docs/patterns/backtracking_exploration/templates.md) | LeetCode 39, 40, 46, 47, 51, 77, 78, 79, 90, 93, 131, 216 |
| `GridBFSMultiSource` | *coming soon* | LeetCode 994, 286, 542 |
| `KWayMerge` | *coming soon* | LeetCode 23, 21, 88 |
| `BinarySearchBoundary` | *coming soon* | LeetCode 4, 33, 34, 35 |
| `LinkedListInPlaceReversal` | *coming soon* | LeetCode 25, 206, 92 |
| `MonotonicStack` | *coming soon* | LeetCode 84, 85, 496 |

ğŸ‘‰ **[View All Pattern Guides â†’](docs/patterns/README.md)**

---

## ğŸ“– Usage Guide

### âŒ¨ï¸ VS Code Integration

**Keyboard Shortcuts:**

| Shortcut | Action |
|:---------|:-------|
| `Ctrl+Shift+B` | Run all tests for current file |
| `F5` | Debug with test case #1 |

> **Note:** Open a solution file in `solutions/` before using shortcuts.

**Common Tasks** (`Ctrl+Shift+P` â†’ "Tasks: Run Task"):

| Task | Description |
|:-----|:------------|
| Run all tests | Execute all test cases |
| Run case #1 / #2 / #3 | Run specific test case |
| Benchmark | Show execution times |
| Run all solutions | Compare all implementations |
| Run with generated (10) | Static + 10 generated cases |

> ğŸ“– **Complete Reference**: See [VSCode Setup Guide](docs/contributors/vscode-setup.md) for all 14 tasks, 11 debug configurations, workflow examples, and customization.

### ğŸ’» Command Line Interface

> ğŸ“– **Complete Reference**: See [Testing & Validation Guide](docs/runner/README.md) for full CLI options, usage examples, and advanced features. This is the **core testing engine** that powers automated testing, benchmarking, random test generation, and complexity estimation.

```bash
# Run all test cases
python runner/test_runner.py <problem_name>

# Run specific test case
python runner/case_runner.py <problem_name> <case_number>

# Run with benchmarking
python runner/test_runner.py <problem_name> --benchmark

# Run all solutions
python runner/test_runner.py <problem_name> --all

# Generate random tests
python runner/test_runner.py <problem_name> --generate 10

# Estimate time complexity
python runner/test_runner.py <problem_name> --estimate

# Memory profiling (optional)
python runner/test_runner.py <problem_name> --memory-trace
python runner/test_runner.py <problem_name> --all --trace-compare

# Save failing generated cases for reproduction
python runner/test_runner.py <problem_name> --generate 100 --seed 12345 --save-failed
```

**Optional runner dependencies (enable extra features):**

```bash
pip install big-O psutil sparklines tabulate
```

### ğŸ“ Solution File Format

```python
# solutions/0001_two_sum.py
from typing import List
from _runner import get_solver

SOLUTIONS = {
    "default": {
        "class": "Solution",
        "method": "twoSum",
        "complexity": "O(n) time, O(n) space",
        "description": "Single pass with hash map",
    },
}

class Solution:
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        seen = {}
        for i, num in enumerate(nums):
            complement = target - num
            if complement in seen:
                return [seen[complement], i]
            seen[num] = i
        return []

def solve():
    import sys
    import json
    lines = sys.stdin.read().strip().split('\n')
    
    # Parse input
    # Canonical format: JSON literal, one value per line
    nums = json.loads(lines[0])
    target = json.loads(lines[1])
    
    # Run solution (polymorphic dispatch)
    solver = get_solver(SOLUTIONS)
    result = solver.twoSum(nums, target)
    print(json.dumps(result, separators=(',', ':')))

if __name__ == "__main__":
    solve()
```

> ğŸ“– See [`docs/contracts/solution-contract.md`](docs/contracts/solution-contract.md) for the complete specification.

### ğŸ“‹ Test File Format

| Specification | Requirement |
|:--------------|:------------|
| Line Ending | **LF** (Unix format, `\n`) |
| Encoding | UTF-8 |
| File Ending | Single newline at end |
| Naming | `{number}_{name}_{case}.in/.out` |

**Input file** (`tests/0001_two_sum_1.in`):
```
[2,7,11,15]
9
```

**Output file** (`tests/0001_two_sum_1.out`):
```
[0,1]
```

> ğŸ“– Full contract: [`docs/contracts/test-file-format.md`](docs/contracts/test-file-format.md)

---

## ğŸ”§ Advanced Features

### ğŸš€ Multi-Solution Benchmarking

Compare multiple approaches for the same problem using the **polymorphic pattern**:

```python
# solutions/0023_merge_k_sorted_lists.py
from _runner import get_solver

SOLUTIONS = {
    "default": {
        "class": "SolutionHeap",
        "method": "mergeKLists",
        "complexity": "O(N log k)",
        "description": "Min Heap approach"
    },
    "divide": {
        "class": "SolutionDivideConquer",
        "method": "mergeKLists",
        "complexity": "O(N log k)",
        "description": "Divide and Conquer"
    },
    "greedy": {
        "class": "SolutionGreedy",
        "method": "mergeKLists",
        "complexity": "O(kN)",
        "description": "Greedy comparison"
    },
}

class SolutionHeap:
    def mergeKLists(self, lists):
        # Heap implementation
        pass

class SolutionDivideConquer:
    def mergeKLists(self, lists):
        # Divide & Conquer implementation
        pass

class SolutionGreedy:
    def mergeKLists(self, lists):
        # Greedy implementation
        pass

def solve():
    # ... parse input ...
    solver = get_solver(SOLUTIONS)
    result = solver.mergeKLists(lists)
    print(result)
```

**Run commands:**

```bash
# Run specific solution
python runner/test_runner.py 0023_merge_k_sorted_lists --method heap

# Compare all solutions
python runner/test_runner.py 0023_merge_k_sorted_lists --all --benchmark
```

**Output:**

```
============================================================
ğŸ“Š Performance Comparison
============================================================
Method               Avg Time     Complexity      Pass Rate
------------------------------------------------------------
heap                    44.36ms   O(N log k)      3/3
divide                  44.48ms   O(N log k)      3/3
greedy                  44.82ms   O(kN)           3/3
============================================================
```

Create with template: `scripts\new_problem.bat 0023_merge_k_lists --multi`

> ğŸ“– See [`docs/contracts/solution-contract.md`](docs/contracts/solution-contract.md#solutions-metadata) for complete SOLUTIONS schema and validation rules.

### ğŸ”€ Flexible Output Validation

For problems with multiple valid answers ("return in any order"):

**Validation Modes:**

| Mode | Description | Requires `.out` |
|:-----|:------------|:---------------:|
| `[judge]` | Custom validation with reference | âœ… |
| `[judge-only]` | Custom validation only | âŒ |
| `[exact]` | Exact string match | âœ… |
| `[sorted]` | Sort before comparison | âœ… |
| `[set]` | Set comparison | âœ… |

**JUDGE_FUNC (Recommended):**

```python
def judge(actual: list, expected, input_data: str) -> bool:
    """Validate N-Queens solution."""
    n = int(input_data.strip())
    
    # Validate each board
    for board in actual:
        if not is_valid_n_queens(board, n):
            return False
    
    # Check count if expected exists
    if expected is not None:
        return len(actual) == len(expected)
    
    return True

JUDGE_FUNC = judge
```

**COMPARE_MODE (Simple Cases):**

```python
COMPARE_MODE = "sorted"  # Options: "exact" | "sorted" | "set"
```

> ğŸ“– See [`docs/contracts/solution-contract.md`](docs/contracts/solution-contract.md#validation-judge_func--compare_mode) for complete JUDGE_FUNC signature and validation rules.

### ğŸ² Random Test Generation

Create a generator file with the same name as your solution:

```python
# generators/0004_median_of_two_sorted_arrays.py
import random
from typing import Iterator, Optional

def generate(count: int = 10, seed: Optional[int] = None) -> Iterator[str]:
    """Generate random test cases."""
    import json
    if seed is not None:
        random.seed(seed)
    
    # Edge cases first
    yield "[]\n[1]"
    yield "[1]\n[]"
    
    # Random cases
    for _ in range(count - 2):
        m = random.randint(0, 1000)
        n = random.randint(0, 1000)
        nums1 = sorted(random.randint(-10**6, 10**6) for _ in range(m))
        nums2 = sorted(random.randint(-10**6, 10**6) for _ in range(n))
        yield f"{json.dumps(nums1, separators=(',', ':'))}\n{json.dumps(nums2, separators=(',', ':'))}"
```

**Usage:**

```bash
# Run static + generated tests
python runner/test_runner.py 0004_median --generate 10

# Only generated tests
python runner/test_runner.py 0004_median --generate-only 100

# Reproducible with seed
python runner/test_runner.py 0004_median --generate 10 --seed 42

# Save failing cases
python runner/test_runner.py 0004_median --generate 10 --save-failed
```

> ğŸ“– See [`docs/contracts/generator-contract.md`](docs/contracts/generator-contract.md) for complete generator specification and best practices.

### ğŸ“ˆ Time Complexity Estimation

Add a complexity generator function:

```python
# generators/0004_median_of_two_sorted_arrays.py

def generate_for_complexity(n: int) -> str:
    """Generate test case with specific size n."""
    m = random.randint(0, n)
    return _generate_case(m, n - m)
```

**Run estimation:**

```bash
python runner/test_runner.py 0004_median --estimate
```

**Output:**

```
ğŸ“ˆ Running complexity estimation...
   Sizes: [10, 20, 50, 100, 200, 500, 1000, 2000]
   n=   10: 0.0040ms
   n=  100: 0.0082ms
   n= 1000: 0.0685ms
   n= 2000: 0.1796ms

âœ… Estimated: O(n log n)
   Confidence: 1.00
```

---

## ğŸ“ Project Architecture

```
neetcode/
â”‚
â”œâ”€â”€ solutions/                 # ğŸ“ Your solution files
â”‚   â””â”€â”€ 0001_two_sum.py
â”‚
â”œâ”€â”€ practices/                 # ğŸ§  Practice workspace (generated practice files + history)
â”‚   â””â”€â”€ _history/...
â”‚
â”œâ”€â”€ tests/                     # ğŸ“‹ Test cases
â”‚   â”œâ”€â”€ 0001_two_sum_1.in      # Input file
â”‚   â”œâ”€â”€ 0001_two_sum_1.out     # Expected output
â”‚   â””â”€â”€ *_failed_*.in          # Auto-saved failed cases (--save-failed)
â”‚
â”œâ”€â”€ generators/                # ğŸ² Random test generators (optional)
â”‚   â””â”€â”€ 0001_two_sum.py        # generate(count, seed) function
â”‚
â”œâ”€â”€ packages/                  # ğŸ“¦ Core packages (CodeGen, datasource, practice workspace)
â”‚   â”œâ”€â”€ codegen/               # `python -m packages.codegen ...`
â”‚   â”œâ”€â”€ leetcode_datasource/   # LeetCode metadata/source
â”‚   â””â”€â”€ practice_workspace/    # Practice history utilities
â”‚
â”œâ”€â”€ config/                    # âš™ï¸ Living registries / policies
â”‚   â””â”€â”€ problem-support.yaml   # Problem support boundary (tiers/codec hints, etc.)
â”‚
â”œâ”€â”€ runner/                    # ğŸ§ª Core testing & validation engine
â”‚   â”œâ”€â”€ test_runner.py         # CLI entry point & main orchestration
â”‚   â”œâ”€â”€ case_runner.py         # Single case runner (for debugging)
â”‚   â”œâ”€â”€ executor.py            # Test case execution (subprocess)
â”‚   â”œâ”€â”€ compare.py             # Output comparison (exact/sorted/set/judge)
â”‚   â”œâ”€â”€ reporter.py            # Result formatting & benchmark display
â”‚   â”œâ”€â”€ module_loader.py       # Dynamic module loading
â”‚   â”œâ”€â”€ complexity_estimator.py # Time complexity estimation (big_O)
â”‚   â”œâ”€â”€ paths.py               # Path utilities
â”‚   â”œâ”€â”€ io_utils.py            # File I/O operations
â”‚   â”œâ”€â”€ util.py                # Re-exports (backward compatible)
â”‚   â””â”€â”€ README.md              # Quick reference guide
â”‚
â”‚   ğŸ“– See [Testing & Validation Guide](docs/runner/README.md) â€” Core engine for automated testing, benchmarking, random test generation, and complexity estimation
â”‚
â”œâ”€â”€ templates/                 # ğŸ“„ Problem templates
â”‚   â”œâ”€â”€ template_solution.py       # Single solution template
â”‚   â”œâ”€â”€ template_solution_multi.py # Multi-solution (polymorphic)
â”‚   â””â”€â”€ template_test.txt          # Test case template
â”‚
â”œâ”€â”€ .vscode/                   # ğŸ”§ VS Code integration
â”‚   â”œâ”€â”€ settings.json          # Python environment settings
â”‚   â”œâ”€â”€ tasks.json             # Ctrl+Shift+B shortcuts (14 tasks)
â”‚   â””â”€â”€ launch.json            # F5 debug configurations (11 configs)
â”‚
â”‚   ğŸ“– See [VSCode Setup Guide](docs/contributors/vscode-setup.md) â€” Tasks, debug configs, workflow examples
â”‚
â”œâ”€â”€ docs/                      # ğŸ“š Documentation (MkDocs)
â”‚   â”œâ”€â”€ index.md               # Homepage (English)
â”‚   â”œâ”€â”€ index_zh-TW.md         # Homepage (ç¹é«”ä¸­æ–‡)
â”‚   â”œâ”€â”€ contributors/          # Maintainer documentation
â”‚   â”‚   â”œâ”€â”€ README.md          # Full maintainer guide
â”‚   â”‚   â”œâ”€â”€ testing.md         # Complete testing documentation
â”‚   â”‚   â”œâ”€â”€ vscode-setup.md    # VS Code tasks & debug configs
â”‚   â”‚   â”œâ”€â”€ virtual-env-setup.md  # Virtual environment setup
â”‚   â”‚   â””â”€â”€ documentation-architecture.md  # Documentation structure
â”‚   â”œâ”€â”€ tools/                 # Tools documentation
â”‚   â”‚   â”œâ”€â”€ README.md          # Complete tools reference
â”‚   â”‚   â”œâ”€â”€ ai-markmap-agent/  # AI Markmap Agent docs
â”‚   â”‚   â”œâ”€â”€ mindmaps/          # Mind Maps Generator docs
â”‚   â”‚   â””â”€â”€ patterndocs/       # Pattern Docs Generator docs
â”‚   â”œâ”€â”€ mindmaps/              # Generated mind map markdown
â”‚   â”œâ”€â”€ patterns/              # Generated pattern documentation
â”‚   â”œâ”€â”€ pages/                 # Generated HTML (gitignored)
â”‚   â”œâ”€â”€ assets/                # Documentation assets (images, CSS, JS)
â”‚   â”œâ”€â”€ overrides/             # MkDocs theme overrides
â”‚   â”œâ”€â”€ getting-started/       # Getting started guides
â”‚   â””â”€â”€ stylesheets/           # Custom CSS
â”‚
â”œâ”€â”€ tools/                     # ğŸ› ï¸ Utility scripts
â”‚   â”œâ”€â”€ mindmaps/              # ğŸ—ºï¸ Mind map tools (all integrated)
â”‚   â”‚   â”œâ”€â”€ core/              # Core modules
â”‚   â”‚   â”œâ”€â”€ ai-markmap-agent/  # ğŸ¤– AI Markmap Agent (multi-agent pipeline)
â”‚   â”‚   â”œâ”€â”€ ai_mindmap/        # AI mind map modules
â”‚   â”‚   â”œâ”€â”€ hooks/             # Git hooks
â”‚   â”‚   â”œâ”€â”€ prompts/           # AI prompts
â”‚   â”‚   â”œâ”€â”€ shared/            # Shared utilities
â”‚   â”‚   â”œâ”€â”€ tests/             # Tests
â”‚   â”‚   â”œâ”€â”€ generate_mindmaps.py       # Rule-based generator (entry)
â”‚   â”‚   â”œâ”€â”€ generate_mindmaps_ai.py    # AI generator (entry)
â”‚   â”‚   â”œâ”€â”€ generate_mindmaps.toml     # Rule-based configuration
â”‚   â”‚   â”œâ”€â”€ generate_mindmaps_ai.toml  # AI configuration
â”‚   â”‚   â”œâ”€â”€ sync_mindmap_html.py       # Sync HTML
â”‚   â”‚   â”œâ”€â”€ text_to_mindmap.py         # Text to mindmap
â”‚   â”‚   â””â”€â”€ html_meta_description_generator.py  # SEO meta descriptions
â”‚   â”œâ”€â”€ patterndocs/           # ğŸ“š Pattern documentation generator
â”‚   â”‚   â””â”€â”€ generate_pattern_docs.py   # Entry script
â”‚   â”œâ”€â”€ review-code/           # ğŸ” Code review & validation
â”‚   â”‚   â””â”€â”€ validation/        # Validation tools
â”‚   â”‚       â”œâ”€â”€ check_solutions.py
â”‚   â”‚       â”œâ”€â”€ check_test_files.py
â”‚   â”‚       â””â”€â”€ run_format_tests.py
â”‚   â”œâ”€â”€ docstring/             # ğŸ“ Docstring tools
â”‚   â”œâ”€â”€ leetcode-api/          # ğŸ”— LeetCode API
â”‚   â”‚   â””â”€â”€ crawler/           # Crawler tools
â”‚   â”œâ”€â”€ maintenance/           # ğŸ”§ Maintenance tools
â”‚   â”‚   â””â”€â”€ doc-naming/        # Documentation naming tools
â”‚   â””â”€â”€ _staging/              # ğŸ“¦ Staging area (to be organized)
â”‚
â”œâ”€â”€ ontology/                  # ğŸ§¬ Algorithm ontology (TOML)
â”‚   â”œâ”€â”€ api_kernels.toml       # API kernel definitions
â”‚   â”œâ”€â”€ patterns.toml          # Pattern definitions
â”‚   â”œâ”€â”€ algorithms.toml        # Algorithm definitions
â”‚   â”œâ”€â”€ data_structures.toml   # Data structure definitions
â”‚   â”œâ”€â”€ companies.toml         # Company definitions
â”‚   â”œâ”€â”€ topics.toml            # Topic definitions
â”‚   â”œâ”€â”€ difficulties.toml      # Difficulty levels
â”‚   â”œâ”€â”€ families.toml          # Problem family definitions
â”‚   â””â”€â”€ roadmaps.toml          # Roadmap definitions
â”‚
â”œâ”€â”€ meta/                      # ğŸ“Š Problem & pattern metadata
â”‚   â”œâ”€â”€ problems/              # Problem metadata (one TOML per problem)
â”‚   â”‚   â””â”€â”€ *.toml
â”‚   â””â”€â”€ patterns/              # Pattern documentation sources
â”‚       â””â”€â”€ <pattern_name>/    # Pattern-specific markdown
â”‚
â”œâ”€â”€ roadmaps/                  # ğŸ—ºï¸ Learning path definitions
â”‚   â”œâ”€â”€ neetcode_150.toml
â”‚   â”œâ”€â”€ blind_75.toml
â”‚   â””â”€â”€ sliding_window_path.toml
â”‚
â”œâ”€â”€ .dev/                      # ğŸ§ª Maintainer zone (unit tests)
â”‚   â”œâ”€â”€ tests/                 # Unit test suite (150+ cases)
â”‚   â”œâ”€â”€ tests_solutions/       # Solution validation tests
â”‚   â”œâ”€â”€ scripts/run_tests.bat/.sh  # Run runner unit tests
â”‚   â”œâ”€â”€ run_all_tests.bat/.sh  # Run all unit tests
â”‚   â”œâ”€â”€ run_tests_solutions.bat/.sh  # Run solution tests
â”‚   â”œâ”€â”€ testing.md             # Testing documentation
â”‚   â”œâ”€â”€ virtual-env-setup.md   # Virtual environment guide
â”‚   â””â”€â”€ README.md              # Maintainer guide
â”‚
â”œâ”€â”€ .github/                   # ğŸš€ GitHub configuration
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-pages.yml   # GitHub Pages deployment
â”‚
â”œâ”€â”€ leetcode/                  # ğŸ Python virtual environment (3.11)
â”‚
â”œâ”€â”€ scripts/                   # ğŸ”§ Utility scripts
â”‚   â”œâ”€â”€ new_problem.bat / .sh  # Create new problem (wrapper around packages/codegen)
â”‚   â”œâ”€â”€ run_tests.bat / .sh    # Run all tests for a problem
â”‚   â”œâ”€â”€ run_case.bat / .sh     # Run single test case
â”‚   â””â”€â”€ build_docs.bat / .sh   # Build documentation site
â”‚
â”œâ”€â”€ mkdocs_plugins/            # ğŸ”Œ MkDocs plugins
â”‚   â””â”€â”€ mindmaps_lastmod.py    # Last modified date plugin
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ pyproject.toml             # Project configuration
â”œâ”€â”€ mkdocs.yml                 # MkDocs configuration
â”œâ”€â”€ pytest.ini                 # pytest configuration
â”œâ”€â”€ README.md                  # This file (English)
â””â”€â”€ README_zh-TW.md            # ç¹é«”ä¸­æ–‡ç‰ˆ
```

### Directory Guide

| Directory | Purpose | Target Audience |
|:----------|:--------|:----------------|
| `solutions/` | Write your solutions here | âœ… All users |
| `practices/` | Practice workspace (generated practice files + history) | âœ… All users |
| `tests/` | Add test cases (.in/.out) | âœ… All users |
| `generators/` | Random test generators | âœ… All users |
| `runner/` | Test execution engine | ğŸ”§ Contributors |
| `packages/` | Core packages (CodeGen, datasource, practice workspace) | ğŸ”§ Contributors |
| `config/` | Problem support registry & policy | ğŸ”§ Contributors |
| `templates/` | Problem templates | âœ… All users |
| `.vscode/` | VS Code configuration | âœ… All users |
| `docs/` | MkDocs documentation | ğŸ”§ Contributors |
| `tools/` | Documentation generators | ğŸ”§ Contributors |
| `ontology/` | Algorithm ontology data | ğŸ”§ Contributors |
| `meta/` | Problem/pattern metadata | ğŸ”§ Contributors |
| `.dev/` | Unit tests (150+ cases) | ğŸ”§ Maintainers |

> **ğŸ“ Note:** Files in `docs/mindmaps/`, `docs/patterns/`, and `docs/pages/` are auto-generated. Edit the source files in `ontology/`, `meta/`, and `tools/` instead.

### Documentation Guide

Documentation is organized by **target audience**:

| Location | Purpose | Audience |
|:---------|:--------|:---------|
| `docs/` | User documentation (published to website) | âœ… Users |
| `tools/README.md` | Developer tools reference | ğŸ”§ Contributors |
| `tools/*/README.md` | Module technical details | ğŸ”§ Contributors |
| `.dev/` | Maintainer documentation | ğŸ”§ Maintainers |

**Key Documentation Files:**

| Document | Description |
|:---------|:------------|
| [`docs/contracts/solution-contract.md`](docs/contracts/solution-contract.md) | Solution file specification |
| [`docs/contracts/generator-contract.md`](docs/contracts/generator-contract.md) | Generator file specification |
| [`docs/contracts/test-file-format.md`](docs/contracts/test-file-format.md) | Canonical `.in`/`.out` format (JSON literal, one value per line) |
| [`docs/contracts/codec.md`](docs/contracts/codec.md) | Codec contract (import/inline helpers, semantics) |
| [`docs/contracts/problem-support-boundary.md`](docs/contracts/problem-support-boundary.md) | Problem support boundary & hard rules |
| [`docs/packages/codegen/README.md`](docs/packages/codegen/README.md) | CodeGen reference (new/practice/check/migrate) |
| [`docs/runner/README.md`](docs/runner/README.md) | Runner spec (CLI options, memory profiling, output format) |
| [`docs/tools/README.md`](docs/tools/README.md) | Complete tools reference |
| [`docs/contributors/README.md`](docs/contributors/README.md) | Maintainer guide |
| [`docs/contributors/documentation-naming.md`](docs/contributors/documentation-naming.md) | Documentation naming convention (kebab-case) |
| [`docs/contributors/documentation-architecture.md`](docs/contributors/documentation-architecture.md) | Documentation structure |

---

## â“ Frequently Asked Questions

**What problems does this framework solve?**

- Running multiple algorithm implementations automatically
- Generating reproducible random test data for stress testing
- Benchmarking solutions to identify performance differences
- Debugging LeetCode-style problems with VS Code integration
- Validating outputs using custom logic beyond simple file comparison

**How is this different from copying LeetCode solutions?**

This is not a solution collection â€” it's a **testing infrastructure**. You write solutions, and the framework:

1. Runs them against static test cases
2. Generates random test cases automatically
3. Validates correctness using custom judge functions
4. Benchmarks multiple solutions against each other
5. Estimates time complexity empirically

**Can I use this for interview preparation?**

Absolutely! The framework is perfect for interview prep:

- Practice writing solutions in **real LeetCode format**
- Find **edge cases you might miss** with random test generation
- See which approach is **actually faster** with benchmarking
- **Debug easily** with VS Code integration

**What Python version is required?**

Python 3.11 â€” matching the [LeetCode official environment](https://support.leetcode.com/hc/en-us/articles/360011833974-What-are-the-environments-for-the-programming-languages).

---

## ğŸ› ï¸ For Contributors

### Running Unit Tests

```bash
# Activate virtual environment
leetcode\Scripts\activate  # Windows
source leetcode/bin/activate  # Linux/macOS

# Run all tests
python -m pytest .dev/tests -v

# With coverage
python -m pytest .dev/tests --cov=runner --cov-report=html
```

### Generate Mind Maps Locally

**AI-Powered (Recommended):**

```bash
# Interactive mode
python tools/mindmaps/generate_mindmaps_ai.py

# With specific goal
python tools/mindmaps/generate_mindmaps_ai.py --goal interview

# Generate multiple languages
# Edit tools/mindmaps/generate_mindmaps_ai.toml: language = ["en", "zh-TW"]
python tools/mindmaps/generate_mindmaps_ai.py
```

Configuration: `tools/mindmaps/generate_mindmaps_ai.toml`

**Rule-Based:**

```bash
# Generate Markdown mind maps
python tools/mindmaps/generate_mindmaps.py

# Generate HTML (interactive) mind maps
python tools/mindmaps/generate_mindmaps.py --html
```

Configuration: `tools/mindmaps/generate_mindmaps.toml`

### Build Documentation Locally

> âš ï¸ **Optional Feature:** Building documentation locally is **completely optional**. Core LeetCode practice functionality works without any documentation build setup.

**Recommended Method (Simple):**

The easiest way to build documentation locally is using the manual scripts:

```bash
# Windows
scripts\build_docs.bat

# Linux/macOS
./scripts/build_docs.sh

# Build and preview locally
scripts\build_docs.bat --serve  # Windows
./scripts/build_docs.sh --serve  # Linux/macOS
```

ğŸ“– **See [Building Documentation Locally (Manual Method)](docs/guides/build-docs-manual.md)** for complete guide.

**Advanced Option (Optional):**

If you want to test the exact GitHub Actions workflow locally, you can use `act`:

ğŸ“– **See [Running GitHub Actions Locally with Act](docs/guides/act-local-github-actions.md)** â€” *Note: Requires Docker and act tool. Only needed if you want to test CI/CD workflows.*

### Documentation

**Core Documentation:**
- [`docs/contributors/README.md`](docs/contributors/README.md) â€” Maintainer guide
- [`docs/contributors/testing.md`](docs/contributors/testing.md) â€” Testing documentation
- [`docs/contributors/vscode-setup.md`](docs/contributors/vscode-setup.md) â€” VS Code tasks, debug configurations, workflow examples
- [`docs/contributors/documentation-naming.md`](docs/contributors/documentation-naming.md) â€” Docs naming convention (kebab-case)
- [`docs/contracts/solution-contract.md`](docs/contracts/solution-contract.md) â€” Solution file specification (SOLUTIONS dict, JUDGE_FUNC)
- [`docs/contracts/generator-contract.md`](docs/contracts/generator-contract.md) â€” Generator file specification (generate(), edge cases, complexity)
- [`docs/contracts/test-file-format.md`](docs/contracts/test-file-format.md) â€” Canonical `.in`/`.out` format (JSON literal, one value per line)
- [`docs/contracts/codec.md`](docs/contracts/codec.md) â€” Codec contract (import/inline helpers, semantics)
- [`docs/contracts/problem-support-boundary.md`](docs/contracts/problem-support-boundary.md) â€” Problem support boundary & hard rules
- [`docs/packages/codegen/README.md`](docs/packages/codegen/README.md) â€” CodeGen reference (new/practice/check/migrate)
- [`docs/runner/README.md`](docs/runner/README.md) â€” Test runner spec (CLI options, memory profiling, output format)
- [`docs/architecture/architecture-migration.md`](docs/architecture/architecture-migration.md) â€” Polymorphic architecture migration guide

**Local Documentation Build (Optional):**
- [`docs/guides/build-docs-manual.md`](docs/guides/build-docs-manual.md) â€” â­ **Recommended:** Simple manual build method
- [`docs/guides/act-local-github-actions.md`](docs/guides/act-local-github-actions.md) â€” Advanced: Test CI/CD workflows locally with act (requires Docker)

**Deployment:**
- [`docs/guides/github-pages-setup.md`](docs/guides/github-pages-setup.md) â€” Deployment guide

---

## ğŸ“œ License

**MIT License** â€” Free for personal learning and educational use.

---

**Built with â¤ï¸ for the competitive programming community**
