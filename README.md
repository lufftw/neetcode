# ğŸ§© NeetCode Practice Framework

<div align="center">

[![GitHub stars](https://img.shields.io/github/stars/lufftw/neetcode?style=for-the-badge&logo=github&color=gold)](https://github.com/lufftw/neetcode/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/lufftw/neetcode?style=for-the-badge&logo=github&color=silver)](https://github.com/lufftw/neetcode/network)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

[![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![VS Code](https://img.shields.io/badge/VS%20Code-Ready-007ACC?style=flat-square&logo=visual-studio-code&logoColor=white)](https://code.visualstudio.com/)
[![Tests](https://img.shields.io/badge/Unit%20Tests-150+-success?style=flat-square&logo=pytest&logoColor=white)](.dev/tests/)
[![Mind Maps](https://img.shields.io/badge/Mind%20Maps-9%20Types-ff69b4?style=flat-square&logo=markmap&logoColor=white)](https://lufftw.github.io/neetcode/mindmaps/)
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen?style=flat-square&logo=git&logoColor=white)](https://github.com/lufftw/neetcode/pulls)

### ğŸ¯ Stop Memorizing. Start Engineering.

*The algorithm practice framework that treats your code like production software.*

[ğŸ“š Documentation](https://lufftw.github.io/neetcode/) &nbsp;â€¢&nbsp; [ğŸ§  Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/) &nbsp;â€¢&nbsp; [ğŸš€ Quick Start](#-quick-start)

**Language / èªè¨€**: [English](README.md) | [ç¹é«”ä¸­æ–‡](README_zh-TW.md)

</div>

---

## ğŸŒŸ What Sets Us Apart

> ğŸ’¡ **"The difference between a good programmer and a great one isn't the algorithm they choose â€” it's how they prove it works."**

<table>
<tr>
<td width="60%">

### ğŸ“¦ Other LeetCode Repos
âŒ Copy solutions, hope they work  
âŒ Manual test cases only  
âŒ No way to compare approaches  
âŒ Memorize patterns blindly  
âŒ No systematic learning path  

</td>
<td width="40%">

### ğŸš€ This Framework
âœ… **Prove** your solution is correct  
âœ… Auto-generate 1000+ test cases  
âœ… Benchmark N solutions side-by-side  
âœ… **Visualize** patterns with mind maps  
âœ… Structured roadmaps (NeetCode 150, Blind 75)  

</td>
</tr>
</table>

### ğŸ§  The Knowledge Graph Advantage

Most people practice algorithms in isolation. We built an **interconnected knowledge system**:

```
ğŸ“ Pattern Hierarchy    â†’  See how API kernels become patterns become solutions
ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Family Derivation    â†’  Understand how problems evolve from base templates  
âš¡ Algorithm Usage      â†’  Know which algorithm applies where
ğŸ¢ Company Coverage     â†’  Target your preparation for specific companies
ğŸ—ºï¸ Learning Roadmaps    â†’  Follow proven paths (NeetCode 150, Blind 75, etc.)
```

**[â†’ Explore 9 Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

### âš™ï¸ Industrial-Strength Testing

Built on principles from **Codeforces, ICPC, and Google's engineering practices**:

| Capability | What It Does | Why It Matters |
|:-----------|:-------------|:---------------|
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility | Find edge cases you never imagined |
| âš–ï¸ **Custom Judge Functions** | ICPC-style validation logic | Multiple correct answers? No problem |
| ğŸ“Š **Multi-Solution Benchmark** | Compare N approaches automatically | Know which is *actually* faster |
| ğŸ“ˆ **Complexity Estimation** | Empirical Big-O analysis | Verify your theoretical claims |
| ğŸ”§ **VS Code Integration** | One-click debug, tasks, shortcuts | Debug algorithms like real software |

---

## ğŸ“‘ Table of Contents

- [Why This Framework?](#-why-this-framework)
- [Quick Start](#-quick-start)
- [Key Features](#-key-features)
- [Interactive Mind Maps](#-interactive-mind-maps)
- [Usage Guide](#-usage-guide)
- [Advanced Features](#-advanced-features)
- [Project Architecture](#-project-architecture)
- [FAQ](#-frequently-asked-questions)
- [For Contributors](#-for-contributors)
- [License](#-license)

---

## â­ Why This Framework?

### The Problem with Traditional Practice

You solve a problem on LeetCode. It passes. But do you *really* know if your solution is correct? What about:

- That edge case with empty input you didn't test?
- The subtle off-by-one error that only appears with large N?
- Whether your O(n log n) claim is actually true?

**Traditional practice leaves these questions unanswered.** This framework answers them definitively.

### What Makes Us Different

| Capability | This Framework | Typical Repos |
|:-----------|:-------------:|:-------------:|
| **Reproducible Random Tests** | âœ… Seeded generators | âŒ Manual only |
| **Custom Judge Functions** | âœ… ICPC/Codeforces style | âŒ String match |
| **Multi-Solution Benchmarking** | âœ… Compare N approaches | âŒ Single solution |
| **VS Code Integration** | âœ… Tasks, Debug, Shortcuts | âŒ CLI only |
| **Stress Testing** | âœ… Generate 1000+ cases | âŒ Limited |
| **Complexity Estimation** | âœ… Automatic Big-O | âŒ None |

### Built For Excellence

| Audience | How We Help |
|:---------|:------------|
| ğŸ† **Competitive Programmers** | Train like Codeforces grandmasters â€” stress test until you break your code, then fix it |
| ğŸ’¼ **FAANG Engineers** | Build interview confidence by proving your solutions work, not just hoping they do |
| ğŸ“ **CS Students** | Learn algorithms the right way â€” through experimentation, not memorization |
| ğŸ‘¨â€ğŸ« **Educators** | Give students industrial-grade tools to validate their understanding |
| ğŸ”¬ **Researchers** | Benchmark algorithm variants at scale with reproducible methodology |

---

## ğŸš€ Quick Start

### 1. Setup Environment

<details>
<summary><strong>Windows (PowerShell)</strong></summary>

```powershell
# Clone and navigate to project
cd C:\path\to\neetcode

# Install Python 3.11 (if needed)
py install 3.11

# Create and activate virtual environment
py -3.11 -m venv leetcode
leetcode\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

</details>

<details>
<summary><strong>Linux / macOS</strong></summary>

```bash
# Using pyenv (recommended)
pyenv install 3.11
pyenv local 3.11

# Create and activate virtual environment
python -m venv leetcode
source leetcode/bin/activate

# Install dependencies
pip install -r requirements.txt

# Make scripts executable
chmod +x run_tests.sh run_case.sh new_problem.sh
```

</details>

### 2. Create Your First Problem

```bash
# Windows
new_problem.bat 0001_two_sum

# Linux/macOS
./new_problem.sh 0001_two_sum
```

This creates:
- `solutions/0001_two_sum.py` â€” Your solution file
- `tests/0001_two_sum_1.in` â€” Test input
- `tests/0001_two_sum_1.out` â€” Expected output

### 3. Run Tests

```bash
# Windows
run_tests.bat 0001_two_sum

# Linux/macOS
./run_tests.sh 0001_two_sum
```

### 4. Debug in VS Code

1. Open any solution file in `solutions/`
2. Press `F5` to debug with test case #1
3. Or press `Ctrl+Shift+B` to run all tests

**That's it!** You're ready to solve problems. ğŸ‰

---

## âœ¨ Key Features

| Feature | Description |
|:--------|:------------|
| ğŸ§ª **Automated Testing** | Run multiple test cases automatically with clear pass/fail reporting and timing |
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility, stress test with 1000+ cases, auto-save failing cases |
| âš–ï¸ **Custom Judge Functions** | Validate multiple correct answers, ICPC-style validation, works without expected output |
| ğŸ“Š **Performance Analysis** | Benchmark multiple solutions, automatic time complexity estimation, side-by-side comparison |
| ğŸ”§ **VS Code Integration** | One-click test execution, integrated debugging, custom tasks and shortcuts |
| ğŸ§  **Interactive Mind Maps** | Visualize algorithm patterns, track learning progress â€” [Explore â†’](https://lufftw.github.io/neetcode/mindmaps/) |

---

## ğŸ§  Interactive Mind Maps

Visualize algorithm patterns, problem relationships, and learning paths:

| Mind Map | Description | Links |
|:---------|:------------|:------|
| ğŸ“ **Pattern Hierarchy** | API Kernels â†’ Patterns â†’ Problems | [Static](docs/mindmaps/pattern_hierarchy.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#pattern-hierarchy) |
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family Derivation** | Base templates â†’ Derived variants | [Static](docs/mindmaps/family_derivation.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#family-derivation) |
| âš¡ **Algorithm Usage** | Problems by algorithm | [Static](docs/mindmaps/algorithm_usage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#algorithm-usage) |
| ğŸ—ï¸ **Data Structure Usage** | Problems by data structure | [Static](docs/mindmaps/data_structure.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#data-structure-usage) |
| ğŸ¢ **Company Coverage** | Company-specific problems | [Static](docs/mindmaps/company_coverage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#company-coverage) |
| ğŸ—ºï¸ **Learning Roadmaps** | NeetCode 150, Blind 75, etc. | [Static](docs/mindmaps/roadmap_paths.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#learning-roadmaps) |
| ğŸ”— **Problem Relations** | Related problems network | [Static](docs/mindmaps/problem_relations.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#problem-relations) |
| ğŸ”€ **Solution Variants** | Multiple approaches | [Static](docs/mindmaps/solution_variants.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#solution-variants) |
| ğŸ“Š **Difficulty Ã— Topics** | Topics by difficulty | [Static](docs/mindmaps/difficulty_topics.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/mindmaps/#difficulty-topics) |

ğŸ‘‰ **[View All Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

---

## ğŸ“– Usage Guide

### âŒ¨ï¸ VS Code Integration

**Keyboard Shortcuts:**

| Shortcut | Action |
|:---------|:-------|
| `Ctrl+Shift+B` | Run all tests for current file |
| `F5` | Debug with test case #1 |

> **Note:** Open a solution file in `solutions/` before using shortcuts.

**Available Tasks** (`Ctrl+Shift+P` â†’ "Tasks: Run Task"):

| Task | Description |
|:-----|:------------|
| Run all tests | Execute all test cases |
| Run case #1 / #2 / #3 | Run specific test case |
| Benchmark | Show execution times |
| Run all solutions | Compare all implementations |
| Run with generated (10) | Static + 10 generated cases |
| Run generated only | Skip static tests |
| Save failed cases | Auto-save failing inputs |

### ğŸ’» Command Line Interface

```bash
# Run all test cases
python runner/test_runner.py <problem_name>

# Run specific test case
python runner/case_runner.py <problem_name> <case_number>

# Run with benchmarking
python runner/test_runner.py <problem_name> --benchmark

# Run all solutions
python runner/test_runner.py <problem_name> --all

# Generate random tests
python runner/test_runner.py <problem_name> --generate 10

# Estimate time complexity
python runner/test_runner.py <problem_name> --estimate
```

### ğŸ“ Solution File Format

```python
# solutions/0001_two_sum.py
from typing import List

class Solution:
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        seen = {}
        for i, num in enumerate(nums):
            complement = target - num
            if complement in seen:
                return [seen[complement], i]
            seen[num] = i
        return []

def solve():
    import sys
    lines = sys.stdin.read().strip().split('\n')
    
    # Parse input
    nums = list(map(int, lines[0].split(',')))
    target = int(lines[1])
    
    # Run solution
    result = Solution().twoSum(nums, target)
    print(result)

if __name__ == "__main__":
    solve()
```

### ğŸ“‹ Test File Format

| Specification | Requirement |
|:--------------|:------------|
| Line Ending | **LF** (Unix format, `\n`) |
| Encoding | UTF-8 |
| File Ending | Single newline at end |
| Naming | `{number}_{name}_{case}.in/.out` |

**Input file** (`tests/0001_two_sum_1.in`):
```
2,7,11,15
9
```

**Output file** (`tests/0001_two_sum_1.out`):
```
[0, 1]
```

---

## ğŸ”§ Advanced Features

### ğŸš€ Multi-Solution Benchmarking

Compare multiple approaches for the same problem:

```python
# solutions/0023_merge_k_sorted_lists.py

SOLUTIONS = {
    "default": {
        "method": "mergeKLists_heap",
        "complexity": "O(N log k)",
        "description": "Min Heap approach"
    },
    "divide": {
        "method": "mergeKLists_divide",
        "complexity": "O(N log k)",
        "description": "Divide and Conquer"
    },
    "greedy": {
        "method": "mergeKLists_greedy",
        "complexity": "O(kN)",
        "description": "Greedy comparison"
    },
}

class Solution:
    def mergeKLists_heap(self, lists):
        # Heap implementation
        pass
    
    def mergeKLists_divide(self, lists):
        # Divide & Conquer implementation
        pass
    
    def mergeKLists_greedy(self, lists):
        # Greedy implementation
        pass
```

**Run commands:**

```bash
# Run specific solution
python runner/test_runner.py 0023_merge_k_sorted_lists --method heap

# Compare all solutions
python runner/test_runner.py 0023_merge_k_sorted_lists --all --benchmark
```

**Output:**

```
============================================================
ğŸ“Š Performance Comparison
============================================================
Method               Avg Time     Complexity      Pass Rate
------------------------------------------------------------
heap                    44.36ms   O(N log k)      3/3
divide                  44.48ms   O(N log k)      3/3
greedy                  44.82ms   O(kN)           3/3
============================================================
```

<details>
<summary><strong>Advanced: Wrapper Pattern for Multiple Classes</strong></summary>

When you need separate classes with the same method name:

```python
class SolutionRecursive:
    def reverseKGroup(self, head, k):
        pass  # Recursive implementation

class SolutionIterative:
    def reverseKGroup(self, head, k):
        pass  # Iterative implementation

# Wrapper functions
def solve_recursive(head, k):
    return SolutionRecursive().reverseKGroup(head, k)

def solve_iterative(head, k):
    return SolutionIterative().reverseKGroup(head, k)

SOLUTIONS = {
    "default": {"method": "solve_iterative", ...},
    "recursive": {"method": "solve_recursive", ...},
}
```

Create with template: `new_problem.bat 0025_reverse_nodes --wrapper`

</details>

### ğŸ”€ Flexible Output Validation

For problems with multiple valid answers ("return in any order"):

**Validation Modes:**

| Mode | Description | Requires `.out` |
|:-----|:------------|:---------------:|
| `[judge]` | Custom validation with reference | âœ… |
| `[judge-only]` | Custom validation only | âŒ |
| `[exact]` | Exact string match | âœ… |
| `[sorted]` | Sort before comparison | âœ… |
| `[set]` | Set comparison | âœ… |

**JUDGE_FUNC (Recommended):**

```python
def judge(actual: list, expected, input_data: str) -> bool:
    """Validate N-Queens solution."""
    n = int(input_data.strip())
    
    # Validate each board
    for board in actual:
        if not is_valid_n_queens(board, n):
            return False
    
    # Check count if expected exists
    if expected is not None:
        return len(actual) == len(expected)
    
    return True

JUDGE_FUNC = judge
```

**COMPARE_MODE (Simple Cases):**

```python
COMPARE_MODE = "sorted"  # Options: "exact" | "sorted" | "set"
```

### ğŸ² Random Test Generation

Create a generator file with the same name as your solution:

```python
# generators/0004_median_of_two_sorted_arrays.py
import random
from typing import Iterator, Optional

def generate(count: int = 10, seed: Optional[int] = None) -> Iterator[str]:
    """Generate random test cases."""
    if seed is not None:
        random.seed(seed)
    
    # Edge cases first
    yield "[]\n[1]"
    yield "[1]\n[]"
    
    # Random cases
    for _ in range(count - 2):
        m = random.randint(0, 1000)
        n = random.randint(0, 1000)
        nums1 = sorted(random.randint(-10**6, 10**6) for _ in range(m))
        nums2 = sorted(random.randint(-10**6, 10**6) for _ in range(n))
        yield f"{list(nums1)}\n{list(nums2)}".replace(' ', '')
```

**Usage:**

```bash
# Run static + generated tests
python runner/test_runner.py 0004_median --generate 10

# Only generated tests
python runner/test_runner.py 0004_median --generate-only 100

# Reproducible with seed
python runner/test_runner.py 0004_median --generate 10 --seed 42

# Save failing cases
python runner/test_runner.py 0004_median --generate 10 --save-failed
```

### ğŸ“ˆ Time Complexity Estimation

Add a complexity generator function:

```python
# generators/0004_median_of_two_sorted_arrays.py

def generate_for_complexity(n: int) -> str:
    """Generate test case with specific size n."""
    m = random.randint(0, n)
    return _generate_case(m, n - m)
```

**Run estimation:**

```bash
python runner/test_runner.py 0004_median --estimate
```

**Output:**

```
ğŸ“ˆ Running complexity estimation...
   Sizes: [10, 20, 50, 100, 200, 500, 1000, 2000]
   n=   10: 0.0040ms
   n=  100: 0.0082ms
   n= 1000: 0.0685ms
   n= 2000: 0.1796ms

âœ… Estimated: O(n log n)
   Confidence: 1.00
```

---

## ğŸ“ Project Architecture

```
neetcode/
â”‚
â”œâ”€â”€ solutions/                 # ğŸ“ Your solution files
â”‚   â””â”€â”€ 0001_two_sum.py
â”‚
â”œâ”€â”€ tests/                     # ğŸ“‹ Test cases
â”‚   â”œâ”€â”€ 0001_two_sum_1.in      # Input file
â”‚   â”œâ”€â”€ 0001_two_sum_1.out     # Expected output
â”‚   â””â”€â”€ *_failed_*.in          # Auto-saved failed cases (--save-failed)
â”‚
â”œâ”€â”€ generators/                # ğŸ² Random test generators (optional)
â”‚   â””â”€â”€ 0001_two_sum.py        # generate(count, seed) function
â”‚
â”œâ”€â”€ runner/                    # âš™ï¸ Test execution engine
â”‚   â”œâ”€â”€ test_runner.py         # CLI entry point & main orchestration
â”‚   â”œâ”€â”€ case_runner.py         # Single case runner (for debugging)
â”‚   â”œâ”€â”€ executor.py            # Test case execution (subprocess)
â”‚   â”œâ”€â”€ compare.py             # Output comparison (exact/sorted/set/judge)
â”‚   â”œâ”€â”€ reporter.py            # Result formatting & benchmark display
â”‚   â”œâ”€â”€ module_loader.py       # Dynamic module loading
â”‚   â”œâ”€â”€ complexity_estimator.py # Time complexity estimation (big_O)
â”‚   â”œâ”€â”€ paths.py               # Path utilities
â”‚   â”œâ”€â”€ io_utils.py            # File I/O operations
â”‚   â””â”€â”€ util.py                # Re-exports (backward compatible)
â”‚
â”œâ”€â”€ templates/                 # ğŸ“„ Problem templates
â”‚   â”œâ”€â”€ template_solution.py          # Single solution
â”‚   â”œâ”€â”€ template_solution_multi.py    # Multi-solution (one class)
â”‚   â””â”€â”€ template_solution_wrapper.py  # Multi-solution (wrapper pattern)
â”‚
â”œâ”€â”€ .vscode/                   # ğŸ”§ VS Code integration
â”‚   â”œâ”€â”€ settings.json          # Python environment settings
â”‚   â”œâ”€â”€ tasks.json             # Ctrl+Shift+B shortcuts
â”‚   â””â”€â”€ launch.json            # F5 debug configurations
â”‚
â”œâ”€â”€ docs/                      # ğŸ“š Documentation (MkDocs)
â”‚   â”œâ”€â”€ index.md               # Homepage (English)
â”‚   â”œâ”€â”€ index_zh-TW.md         # Homepage (ç¹é«”ä¸­æ–‡)
â”‚   â”œâ”€â”€ mindmaps/              # Generated mind map markdown
â”‚   â”œâ”€â”€ patterns/              # Generated pattern documentation
â”‚   â”œâ”€â”€ pages/                 # Generated HTML (gitignored)
â”‚   â””â”€â”€ stylesheets/           # Custom CSS
â”‚
â”œâ”€â”€ tools/                     # ğŸ› ï¸ Utility scripts
â”‚   â”œâ”€â”€ generate_mindmaps.py   # Generate mind maps
â”‚   â”œâ”€â”€ generate_mindmaps.toml # Mind maps configuration
â”‚   â”œâ”€â”€ generate_pattern_docs.py # Generate pattern docs
â”‚   â””â”€â”€ text_to_mindmap.py     # LLM text-to-mindmap converter
â”‚
â”œâ”€â”€ ontology/                  # ğŸ§¬ Algorithm ontology (TOML)
â”‚   â”œâ”€â”€ api_kernels.toml       # API kernel definitions
â”‚   â”œâ”€â”€ patterns.toml          # Pattern definitions
â”‚   â”œâ”€â”€ algorithms.toml        # Algorithm definitions
â”‚   â”œâ”€â”€ data_structures.toml   # Data structure definitions
â”‚   â”œâ”€â”€ companies.toml         # Company definitions
â”‚   â”œâ”€â”€ topics.toml            # Topic definitions
â”‚   â”œâ”€â”€ difficulties.toml      # Difficulty levels
â”‚   â”œâ”€â”€ families.toml          # Problem family definitions
â”‚   â””â”€â”€ roadmaps.toml          # Roadmap definitions
â”‚
â”œâ”€â”€ meta/                      # ğŸ“Š Problem & pattern metadata
â”‚   â”œâ”€â”€ problems/              # Problem metadata (one TOML per problem)
â”‚   â”‚   â””â”€â”€ *.toml
â”‚   â””â”€â”€ patterns/              # Pattern documentation sources
â”‚       â””â”€â”€ <pattern_name>/    # Pattern-specific markdown
â”‚
â”œâ”€â”€ roadmaps/                  # ğŸ—ºï¸ Learning path definitions
â”‚   â”œâ”€â”€ neetcode_150.toml
â”‚   â”œâ”€â”€ blind_75.toml
â”‚   â””â”€â”€ sliding_window_path.toml
â”‚
â”œâ”€â”€ .dev/                      # ğŸ§ª Maintainer zone (unit tests)
â”‚   â”œâ”€â”€ tests/                 # Unit test suite (150+ cases)
â”‚   â”œâ”€â”€ run_tests.bat/.sh      # Run unit tests
â”‚   â”œâ”€â”€ TESTING.md             # Testing documentation
â”‚   â””â”€â”€ README.md              # Maintainer guide
â”‚
â”œâ”€â”€ .github/                   # ğŸš€ GitHub configuration
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-pages.yml   # GitHub Pages deployment
â”‚
â”œâ”€â”€ leetcode/                  # ğŸ Python virtual environment (3.11)
â”‚
â”œâ”€â”€ run_tests.bat / .sh        # Run all tests for a problem
â”œâ”€â”€ run_case.bat / .sh         # Run single test case
â”œâ”€â”€ new_problem.bat / .sh      # Create new problem from template
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ mkdocs.yml                 # MkDocs configuration
â”œâ”€â”€ pytest.ini                 # pytest configuration
â”œâ”€â”€ README.md                  # This file (English)
â””â”€â”€ README_zh-TW.md            # ç¹é«”ä¸­æ–‡ç‰ˆ
```

### Directory Guide

| Directory | Purpose | Target Audience |
|:----------|:--------|:----------------|
| `solutions/` | Write your solutions here | âœ… All users |
| `tests/` | Add test cases (.in/.out) | âœ… All users |
| `generators/` | Random test generators | âœ… All users |
| `runner/` | Test execution engine | ğŸ”§ Contributors |
| `templates/` | Problem templates | âœ… All users |
| `.vscode/` | VS Code configuration | âœ… All users |
| `docs/` | MkDocs documentation | ğŸ”§ Contributors |
| `tools/` | Documentation generators | ğŸ”§ Contributors |
| `ontology/` | Algorithm ontology data | ğŸ”§ Contributors |
| `meta/` | Problem/pattern metadata | ğŸ”§ Contributors |
| `.dev/` | Unit tests (150+ cases) | ğŸ”§ Maintainers |

> **ğŸ“ Note:** Files in `docs/mindmaps/`, `docs/patterns/`, and `docs/pages/` are auto-generated. Edit the source files in `ontology/`, `meta/`, and `tools/` instead.

---

## â“ Frequently Asked Questions

<details>
<summary><strong>What problems does this framework solve?</strong></summary>

- Running multiple algorithm implementations automatically
- Generating reproducible random test data for stress testing
- Benchmarking solutions to identify performance differences
- Debugging LeetCode-style problems with VS Code integration
- Validating outputs using custom logic beyond simple file comparison

</details>

<details>
<summary><strong>How is this different from copying LeetCode solutions?</strong></summary>

This is not a solution collection â€” it's a **testing infrastructure**. You write solutions, and the framework:

1. Runs them against static test cases
2. Generates random test cases automatically
3. Validates correctness using custom judge functions
4. Benchmarks multiple solutions against each other
5. Estimates time complexity empirically

</details>

<details>
<summary><strong>Can I use this for interview preparation?</strong></summary>

Absolutely! The framework is perfect for interview prep:

- Practice writing solutions in **real LeetCode format**
- Find **edge cases you might miss** with random test generation
- See which approach is **actually faster** with benchmarking
- **Debug easily** with VS Code integration

</details>

<details>
<summary><strong>What Python version is required?</strong></summary>

Python 3.11 â€” matching the [LeetCode official environment](https://support.leetcode.com/hc/en-us/articles/360011833974-What-are-the-environments-for-the-programming-languages).

</details>

---

## ğŸ› ï¸ For Contributors

### Running Unit Tests

```bash
# Activate virtual environment
leetcode\Scripts\activate  # Windows
source leetcode/bin/activate  # Linux/macOS

# Run all tests
python -m pytest .dev/tests -v

# With coverage
python -m pytest .dev/tests --cov=runner --cov-report=html
```

### Generate Mind Maps Locally

```bash
# Generate Markdown mind maps
python tools/generate_mindmaps.py

# Generate HTML (interactive) mind maps
python tools/generate_mindmaps.py --html
```

Configuration: `tools/generate_mindmaps.toml`

### Documentation

- [`.dev/README.md`](.dev/README.md) â€” Maintainer guide
- [`.dev/TESTING.md`](.dev/TESTING.md) â€” Testing documentation
- [`docs/GITHUB_PAGES_SETUP.md`](docs/GITHUB_PAGES_SETUP.md) â€” Deployment guide

---

## ğŸ“œ License

**MIT License** â€” Free for personal learning and educational use.

---

**Built with â¤ï¸ for the competitive programming community**
