# ğŸ§© NeetCode Practice Framework

<!-- 
SEO: leetcode, algorithm, data structure, coding interview, FAANG, competitive programming, neetcode, 
     blind 75, python, mind map, pattern, dynamic programming, interview preparation, knowledge graph
AEO/GEO: A scalable Python framework with knowledge graph-driven learning, AI-powered mind maps,
         industrial-strength testing, and pattern-based learning for algorithm mastery.
-->

[![GitHub stars](https://img.shields.io/github/stars/lufftw/neetcode?style=for-the-badge&logo=github&color=gold)](https://github.com/lufftw/neetcode/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/lufftw/neetcode?style=for-the-badge&logo=github&color=silver)](https://github.com/lufftw/neetcode/network)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

[![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/GPT--Powered-412991?style=flat-square&logo=openai&logoColor=white)](https://openai.com/)
[![VS Code](https://img.shields.io/badge/VS%20Code-007ACC?style=flat-square&logo=visual-studio-code&logoColor=white)](https://code.visualstudio.com/)
[![pytest](https://img.shields.io/badge/150%2B%20Tests-0A9EDC?style=flat-square&logo=pytest&logoColor=white)](https://github.com/lufftw/neetcode/tree/main/.dev/tests)
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen?style=flat-square&logo=git&logoColor=white)](https://github.com/lufftw/neetcode/pulls)

---

### ğŸ¯ Stop Memorizing. Start Engineering.

**A scalable Python framework that transforms LeetCode-style algorithm practice into a knowledge-graph-driven, data-driven, testable, and high-performance workflow â€” with AI-powered mind maps, industrial-strength testing, and pattern-based learning to help developers grow faster and understand algorithms more deeply.**

[ğŸ“š Docs](https://lufftw.github.io/neetcode/) â€¢ [ğŸ¤– AI Mind Maps](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode_ontology_ai_en.html) â€¢ [ğŸ§  Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“ Patterns](docs/patterns/)

[English](https://lufftw.github.io/neetcode/) | [ç¹é«”ä¸­æ–‡](https://lufftw.github.io/neetcode/index_zh-TW/)

---

**Topics:** `knowledge-graph` `ai-powered` `mind-map` `pattern-recognition` `leetcode` `neetcode-150` `blind-75` `stress-testing` `algorithm-engineering` `performance-benchmarking` `data-driven-testing` `random-test-generation` `judge-function` `algorithm-debugging` `competitive-programming` `python` `vscode-integration` `test-automation` `pre-commit` `local-automation` `coding-interview`

---

## ğŸ’ Core Philosophy

> **"Algorithm mastery is not about memorizing 300 solutions â€” it's about internalizing 15 fundamental patterns and knowing precisely when to apply each one."**

This framework embodies three transformative principles:

### ğŸ§¬ Knowledge Graph Architecture

Traditional LeetCode practice treats problems as isolated units. We built an **interconnected ontology system** where:

- **API Kernels** define reusable algorithmic primitives (`SubstringSlidingWindow`, `GridBFS`, `BacktrackExplore`)
- **Patterns** compose kernels into higher-level strategies
- **Problem Families** reveal structural relationships across 300+ problems
- **AI Synthesis** discovers non-obvious connections humans miss

*This is how experts think â€” in abstractions, not in solutions.*

### âš™ï¸ Production-Grade Validation

Your solution passes LeetCode's tests. But is it *correct*? Is it *optimal*? We provide **ICPC/Codeforces-caliber testing infrastructure**:

| Capability | What It Proves |
|:-----------|:---------------|
| ğŸ² **Seeded Random Generation** | Your code handles cases you never imagined |
| âš–ï¸ **Custom Judge Functions** | Multiple valid answers are all accepted |
| ğŸ“Š **Multi-Solution Benchmarking** | Which approach is *actually* faster |
| ğŸ“ˆ **Empirical Complexity Estimation** | Your O(n log n) claim is verified |

*This is how Google engineers validate â€” through exhaustive, reproducible testing.*

### ğŸ¤– AI-Augmented Understanding

We don't just store knowledge â€” we **synthesize insight**:

- AI analyzes the entire ontology to generate **creative, interconnected mind maps**
- Multi-perspective synthesis: Architect Ã— Professor Ã— Engineer Ã— Competitor
- Problems link to **GitHub solutions** (when available) or **LeetCode** (fallback)

*This is how the next generation learns â€” with AI as a thinking partner.*

---

## ğŸŒŸ What Sets Us Apart

> ğŸ’¡ **"The difference between a good programmer and a great one isn't the algorithm they choose â€” it's how they prove it works."**

| ğŸ“¦ Other LeetCode Repos | ğŸš€ NeetCode |
|:------------------------|:------------|
| âŒ Copy solutions, hope they work | âœ… **Prove** your solution is correct |
| âŒ Manual test cases only | âœ… Auto-generate 1000+ test cases |
| âŒ No way to compare approaches | âœ… Benchmark N solutions side-by-side |
| âŒ Memorize patterns blindly | âœ… **Visualize** patterns with mind maps |
| âŒ No systematic learning path | âœ… Structured roadmaps (NeetCode 150, Blind 75) |

### ğŸ§  The Knowledge Graph Advantage

Most people practice algorithms in isolation. We built an **interconnected knowledge system**:

| Mind Map | Description | Link |
|:---------|:------------|:----:|
| ğŸ¤– **AI Ontology Analysis** | AI-powered deep pattern synthesis | [ğŸ”— EN](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode_ontology_ai_en.html) Â· [ğŸ”— ä¸­æ–‡](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode_ontology_ai_zh-TW.html) |
| ğŸ“ **Pattern Hierarchy** | API kernels â†’ patterns â†’ solutions | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/pattern_hierarchy.html) |
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family Derivation** | Base templates â†’ derived variants | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/family_derivation.html) |
| âš¡ **Algorithm Usage** | Know which algorithm applies where | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/algorithm_usage.html) |
| ğŸ¢ **Company Coverage** | Target preparation for specific companies | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/company_coverage.html) |
| ğŸ—ºï¸ **Learning Roadmaps** | NeetCode 150, Blind 75, etc. | [ğŸ”—](https://lufftw.github.io/neetcode/pages/mindmaps/roadmap_paths.html) |

**[â†’ Explore 10+ Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

### âš™ï¸ Industrial-Strength Testing

Built on principles from **Codeforces, ICPC, and Google's engineering practices**:

| Capability | What It Does | Why It Matters |
|:-----------|:-------------|:---------------|
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility | Find edge cases you never imagined |
| âš–ï¸ **Custom Judge Functions** | ICPC-style validation logic | Multiple correct answers? No problem |
| ğŸ“Š **Multi-Solution Benchmark** | Compare N approaches automatically | Know which is *actually* faster |
| ğŸ“ˆ **Complexity Estimation** | Empirical Big-O analysis | Verify your theoretical claims |
| ğŸ”§ **VS Code Integration** | One-click debug, tasks, shortcuts | Debug algorithms like real software |

---

## ğŸ“‘ Table of Contents

- [What Sets Us Apart](#-what-sets-us-apart)
- [Why This Framework?](#-why-this-framework)
- [Quick Start](#-quick-start)
- [Key Features](#-key-features)
- [Interactive Mind Maps](#-interactive-mind-maps)
- [AI Mind Map Generation](#-ai-mind-map-generation)
- [Pattern Documentation](#-pattern-documentation)
- [Usage Guide](#-usage-guide)
- [Advanced Features](#-advanced-features)
- [Project Architecture](#-project-architecture)
- [FAQ](#-frequently-asked-questions)
- [For Contributors](#-for-contributors)
- [License](#-license)

---

## â­ Why This Framework?

### The Problem with Traditional Practice

You solve a problem on LeetCode. It passes. But do you *really* know if your solution is correct? What about:

- That edge case with empty input you didn't test?
- The subtle off-by-one error that only appears with large N?
- Whether your O(n log n) claim is actually true?

**Traditional practice leaves these questions unanswered.** This framework answers them definitively.

### What Makes Us Different

| Capability | This Framework | Typical Repos |
|:-----------|:-------------:|:-------------:|
| **Reproducible Random Tests** | âœ… Seeded generators | âŒ Manual only |
| **Custom Judge Functions** | âœ… ICPC/Codeforces style | âŒ String match |
| **Multi-Solution Benchmarking** | âœ… Compare N approaches | âŒ Single solution |
| **VS Code Integration** | âœ… Tasks, Debug, Shortcuts | âŒ CLI only |
| **Stress Testing** | âœ… Generate 1000+ cases | âŒ Limited |
| **Complexity Estimation** | âœ… Automatic Big-O | âŒ None |

### Built For Excellence

| Audience | How We Help |
|:---------|:------------|
| ğŸ† **Competitive Programmers** | Train like Codeforces grandmasters â€” stress test until you break your code, then fix it |
| ğŸ’¼ **FAANG Engineers** | Build interview confidence by proving your solutions work, not just hoping they do |
| ğŸ“ **CS Students** | Learn algorithms the right way â€” through experimentation, not memorization |
| ğŸ‘¨â€ğŸ« **Educators** | Give students industrial-grade tools to validate their understanding |
| ğŸ”¬ **Researchers** | Benchmark algorithm variants at scale with reproducible methodology |

---

## ğŸš€ Quick Start

### 1. Setup Environment

<details>
<summary><strong>Windows (PowerShell)</strong></summary>

```powershell
# Clone and navigate to project
cd C:\path\to\neetcode

# Install Python 3.11 (if needed)
py install 3.11

# Create and activate virtual environment
py -3.11 -m venv leetcode
leetcode\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

</details>

<details>
<summary><strong>Linux / macOS</strong></summary>

```bash
# Using pyenv (recommended)
pyenv install 3.11
pyenv local 3.11

# Create and activate virtual environment
python -m venv leetcode
source leetcode/bin/activate

# Install dependencies
pip install -r requirements.txt

# Make scripts executable
chmod +x scripts/run_tests.sh scripts/run_case.sh scripts/new_problem.sh
```

</details>

### 2. Create Your First Problem

```bash
# Windows
scripts\new_problem.bat 0001_two_sum

# Linux/macOS
./scripts/new_problem.sh 0001_two_sum
```

This creates:
- `solutions/0001_two_sum.py` â€” Your solution file
- `tests/0001_two_sum_1.in` â€” Test input
- `tests/0001_two_sum_1.out` â€” Expected output

### 3. Run Tests

```bash
# Windows
scripts\run_tests.bat 0001_two_sum

# Linux/macOS
./scripts/run_tests.sh 0001_two_sum
```

### 4. Debug in VS Code

1. Open any solution file in `solutions/`
2. Press `F5` to debug with test case #1
3. Or press `Ctrl+Shift+B` to run all tests

**That's it!** You're ready to solve problems. ğŸ‰

---

## âœ¨ Key Features

| Feature | Description |
|:--------|:------------|
| ğŸ¤– **AI Ontology Analysis** | AI-powered knowledge graph synthesis â€” discover pattern relationships humans miss |
| ğŸ§ª **Automated Testing** | Run multiple test cases automatically with clear pass/fail reporting and timing |
| ğŸ² **Random Test Generation** | Seeded generators for reproducibility, stress test with 1000+ cases, auto-save failing cases |
| âš–ï¸ **Custom Judge Functions** | Validate multiple correct answers, ICPC-style validation, works without expected output |
| ğŸ“Š **Performance Analysis** | Benchmark multiple solutions, automatic time complexity estimation, side-by-side comparison |
| ğŸ”§ **VS Code Integration** | One-click test execution, integrated debugging, custom tasks and shortcuts |
| ğŸ§  **Interactive Mind Maps** | Visualize algorithm patterns, track learning progress â€” [Explore â†’](https://lufftw.github.io/neetcode/mindmaps/) |

---

## ğŸ§  Interactive Mind Maps

Visualize algorithm patterns, problem relationships, and learning paths:

### ğŸ¤– AI-Powered Ontology Analysis (NEW!)

> **"Let AI synthesize what takes humans years to internalize."**

Our **AI Ontology Analyzer** processes the entire knowledge graph â€” API Kernels, Patterns, Algorithms, Data Structures, Problem Families â€” and generates **creative, interconnected mind maps** that reveal insights human-curated lists miss.

| Language | Description | Links |
|:---------|:------------|:------|
| **English** | AI-synthesized pattern relationships | [Static](docs/mindmaps/neetcode_ontology_ai_en.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode_ontology_ai_en.html) |
| **ç¹é«”ä¸­æ–‡** | AI æ™ºèƒ½åˆ†ææ¨¡å¼é—œè¯ | [Static](docs/mindmaps/neetcode_ontology_ai_zh-TW.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/neetcode_ontology_ai_zh-TW.html) |

**What makes it special:**
- ğŸ§¬ **Deep Pattern Synthesis** â€” AI identifies non-obvious connections between patterns
- ğŸ¯ **Smart Linking** â€” Problems link to GitHub solutions (when available) or LeetCode
- ğŸŒ **Multi-language** â€” Generate in English and ç¹é«”ä¸­æ–‡
- â™»ï¸ **Regeneratable** â€” Run `python tools/generate_mindmaps_ai.py` to create fresh insights

---

### ğŸ“š Curated Mind Maps

| Mind Map | Description | Links |
|:---------|:------------|:------|
| ğŸ“ **Pattern Hierarchy** | API Kernels â†’ Patterns â†’ Problems | [Static](docs/mindmaps/pattern_hierarchy.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/pattern_hierarchy.html) |
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family Derivation** | Base templates â†’ Derived variants | [Static](docs/mindmaps/family_derivation.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/family_derivation.html) |
| âš¡ **Algorithm Usage** | Problems by algorithm | [Static](docs/mindmaps/algorithm_usage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/algorithm_usage.html) |
| ğŸ—ï¸ **Data Structure Usage** | Problems by data structure | [Static](docs/mindmaps/data_structure.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/data_structure.html) |
| ğŸ¢ **Company Coverage** | Company-specific problems | [Static](docs/mindmaps/company_coverage.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/company_coverage.html) |
| ğŸ—ºï¸ **Learning Roadmaps** | NeetCode 150, Blind 75, etc. | [Static](docs/mindmaps/roadmap_paths.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/roadmap_paths.html) |
| ğŸ”— **Problem Relations** | Related problems network | [Static](docs/mindmaps/problem_relations.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/problem_relations.html) |
| ğŸ”€ **Solution Variants** | Multiple approaches | [Static](docs/mindmaps/solution_variants.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/solution_variants.html) |
| ğŸ“Š **Difficulty Ã— Topics** | Topics by difficulty | [Static](docs/mindmaps/difficulty_topics.md) Â· [Interactive âœ¨](https://lufftw.github.io/neetcode/pages/mindmaps/difficulty_topics.html) |

ğŸ‘‰ **[View All Interactive Mind Maps](https://lufftw.github.io/neetcode/mindmaps/)**

---

## ğŸ¤– AI Mind Map Generation

> **"The synthesis of a Software Architect's system thinking, an Algorithm Professor's pedagogical wisdom, a Principal Engineer's battle-tested experience, and a Competitive Programming Champion's pattern recognition â€” all unified through AI."**

### The Vision

Traditional algorithm learning resources present knowledge in isolation. Our **AI Ontology Analyzer** takes a fundamentally different approach:

| Traditional Approach | Our AI Approach |
|:---------------------|:----------------|
| Static problem lists | Dynamic knowledge graph synthesis |
| Manual categorization | AI-discovered pattern relationships |
| Single perspective | Multi-perspective expert synthesis |
| Memorize solutions | Understand interconnections |

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KNOWLEDGE GRAPH INPUT                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ontology/          â”‚  meta/problems/     â”‚  docs/patterns/     â”‚
â”‚  â”œâ”€â”€ api_kernels    â”‚  â”œâ”€â”€ 0001_*.toml    â”‚  â”œâ”€â”€ sliding_window â”‚
â”‚  â”œâ”€â”€ patterns       â”‚  â”œâ”€â”€ 0003_*.toml    â”‚  â””â”€â”€ ...            â”‚
â”‚  â”œâ”€â”€ algorithms     â”‚  â””â”€â”€ ...            â”‚                     â”‚
â”‚  â””â”€â”€ ...            â”‚                     â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI SYNTHESIS ENGINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ—ï¸ Software Architect    â†’ System-level pattern organization   â”‚
â”‚  ğŸ“š Algorithm Professor   â†’ Pedagogical structure & progression â”‚
â”‚  âš™ï¸ Principal Engineer    â†’ Practical applicability & trade-offsâ”‚
â”‚  ğŸ† Competitive Champion  â†’ Pattern recognition shortcuts       â”‚
â”‚  ğŸ¨ API Designer          â†’ Clean knowledge interfaces          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTELLIGENT OUTPUT                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Smart Links: GitHub solution (if exists) â†’ LeetCode fallbackâ”‚
â”‚  âœ… Multi-language: EN / ç¹é«”ä¸­æ–‡ / ç®€ä½“ä¸­æ–‡                      â”‚
â”‚  âœ… Markmap format: Interactive, collapsible, beautiful         â”‚
â”‚  âœ… Custom goals: Interview prep / Systematic learning / Review â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Start

```bash
# Interactive mode (recommended)
python tools/generate_mindmaps_ai.py

# Specific goals
python tools/generate_mindmaps_ai.py --goal interview        # Interview preparation
python tools/generate_mindmaps_ai.py --goal systematic       # Learning roadmap
python tools/generate_mindmaps_ai.py --goal pattern_mastery  # Deep pattern analysis

# Focus on specific topic
python tools/generate_mindmaps_ai.py --topic sliding_window
python tools/generate_mindmaps_ai.py --topic dynamic_programming

# Multiple languages
# Configure in tools/mindmap_ai_config.toml:
# language = ["en", "zh-TW"]
```

### ğŸ”„ Automatic Generation (Local CI/CD)

**Auto-generate AI mind maps on commit** using pre-commit hooks:

```bash
# Install pre-commit hooks
pip install pre-commit
pre-commit install
```

When you commit changes to `ontology/`, `meta/problems/`, or `tools/generate_mindmaps.py`, the hook automatically runs AI mind map generation.

**Skip when needed:**
```bash
# Skip with commit message
git commit -m "Update ontology [skip-ai]"

# Skip with environment variable
SKIP_AI_MINDMAPS=true git commit -m "Update ontology"
```

> ğŸ“– See [tools/README.md](tools/README.md#-local-cicd-automation) for complete setup and usage guide.

### Configuration

Edit `tools/mindmap_ai_config.toml` to customize:

| Section | What You Can Configure |
|:--------|:-----------------------|
| `[model]` | LLM model, temperature, max tokens |
| `[output]` | Directory, filename, HTML generation |
| `[ontology]` | Which knowledge graph data to include |
| `[problems]` | Problem filters (difficulty, topics, roadmaps) |
| `[generation]` | Goal, style, custom instructions |
| `[links]` | GitHub repo URL, branch, link format |
| `[advanced]` | Output language(s), complexity inclusion |

### The Intelligence Behind It

The AI doesn't just reorganize data â€” it **synthesizes understanding** from multiple expert perspectives:

| Perspective | Contribution to Mind Map |
|:------------|:-------------------------|
| ğŸ—ï¸ **Software Architect** | Identifies abstraction layers, sees patterns as reusable components |
| ğŸ“š **Algorithm Professor** | Structures learning progression, explains "why" not just "how" |
| âš™ï¸ **Principal Engineer** | Highlights production trade-offs, real-world applicability |
| ğŸ† **Competitive Champion** | Surfaces pattern-matching shortcuts, time-pressure optimizations |
| ğŸ¨ **API Designer** | Creates clean knowledge interfaces, consistent naming |
| ğŸ‘¥ **Open Source Advocate** | Makes knowledge discoverable, contribution-friendly |

### Output Examples

**With Solution (links to GitHub):**
```markdown
- [LeetCode 3 - Longest Substring Without Repeating](https://github.com/lufftw/neetcode/blob/main/solutions/0003_longest_substring_without_repeating_characters.py)
```

**Without Solution (links to LeetCode):**
```markdown
- [LeetCode 121 - Best Time to Buy and Sell Stock](https://leetcode.com/problems/best-time-to-buy-and-sell-stock/)
```

### No API Key? No Problem

The generator saves the complete prompt to `tools/prompts/generated/mindmap_prompt.md`. Copy and paste it into ChatGPT, Claude, or any LLM web interface.

---

## ğŸ“ Pattern Documentation

> **"Don't memorize 200 problems. Master 10 patterns."**

Each API Kernel has a dedicated pattern guide with **base template**, **variations**, and **copy-paste ready code**.

| API Kernel | Guide | Problems |
|:-----------|:-----:|:---------|
| `SubstringSlidingWindow` | [ğŸ“–](docs/patterns/sliding_window.md) | LeetCode 3, 76, 159, 209, 340, 438, 567 |
| `TwoPointersTraversal` | [ğŸ“–](docs/patterns/two_pointers.md) | LeetCode 1, 11, 15, 16, 21, 26, 27, 75, 88, 125, 141, 142, 167, 202, 283, 680, 876 |
| `GridBFSMultiSource` | *soon* | LeetCode 994, 286, 542 |
| `BacktrackingExploration` | *soon* | LeetCode 51, 52, 46, 78 |
| `KWayMerge` | *soon* | LeetCode 23, 21, 88 |
| `BinarySearchBoundary` | *soon* | LeetCode 4, 33, 34, 35 |

ğŸ‘‰ **[View All Pattern Guides â†’](docs/patterns/README.md)**

---

## ğŸ“– Usage Guide

### âŒ¨ï¸ VS Code Integration

**Keyboard Shortcuts:**

| Shortcut | Action |
|:---------|:-------|
| `Ctrl+Shift+B` | Run all tests for current file |
| `F5` | Debug with test case #1 |

> **Note:** Open a solution file in `solutions/` before using shortcuts.

**Available Tasks** (`Ctrl+Shift+P` â†’ "Tasks: Run Task"):

| Task | Description |
|:-----|:------------|
| Run all tests | Execute all test cases |
| Run case #1 / #2 / #3 | Run specific test case |
| Benchmark | Show execution times |
| Run all solutions | Compare all implementations |
| Run with generated (10) | Static + 10 generated cases |
| Run generated only | Skip static tests |
| Save failed cases | Auto-save failing inputs |

### ğŸ’» Command Line Interface

```bash
# Run all test cases
python runner/test_runner.py <problem_name>

# Run specific test case
python runner/case_runner.py <problem_name> <case_number>

# Run with benchmarking
python runner/test_runner.py <problem_name> --benchmark

# Run all solutions
python runner/test_runner.py <problem_name> --all

# Generate random tests
python runner/test_runner.py <problem_name> --generate 10

# Estimate time complexity
python runner/test_runner.py <problem_name> --estimate
```

### ğŸ“ Solution File Format

```python
# solutions/0001_two_sum.py
from typing import List
from _runner import get_solver

SOLUTIONS = {
    "default": {
        "class": "Solution",
        "method": "twoSum",
        "complexity": "O(n) time, O(n) space",
        "description": "Single pass with hash map",
    },
}

class Solution:
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        seen = {}
        for i, num in enumerate(nums):
            complement = target - num
            if complement in seen:
                return [seen[complement], i]
            seen[num] = i
        return []

def solve():
    import sys
    lines = sys.stdin.read().strip().split('\n')
    
    # Parse input
    nums = list(map(int, lines[0].split(',')))
    target = int(lines[1])
    
    # Run solution (polymorphic dispatch)
    solver = get_solver(SOLUTIONS)
    result = solver.twoSum(nums, target)
    print(result)

if __name__ == "__main__":
    solve()
```

> ğŸ“– See [`docs/SOLUTION_CONTRACT.md`](docs/SOLUTION_CONTRACT.md) for the complete specification.

### ğŸ“‹ Test File Format

| Specification | Requirement |
|:--------------|:------------|
| Line Ending | **LF** (Unix format, `\n`) |
| Encoding | UTF-8 |
| File Ending | Single newline at end |
| Naming | `{number}_{name}_{case}.in/.out` |

**Input file** (`tests/0001_two_sum_1.in`):
```
2,7,11,15
9
```

**Output file** (`tests/0001_two_sum_1.out`):
```
[0, 1]
```

---

## ğŸ”§ Advanced Features

### ğŸš€ Multi-Solution Benchmarking

Compare multiple approaches for the same problem using the **polymorphic pattern**:

```python
# solutions/0023_merge_k_sorted_lists.py
from _runner import get_solver

SOLUTIONS = {
    "default": {
        "class": "SolutionHeap",
        "method": "mergeKLists",
        "complexity": "O(N log k)",
        "description": "Min Heap approach"
    },
    "divide": {
        "class": "SolutionDivideConquer",
        "method": "mergeKLists",
        "complexity": "O(N log k)",
        "description": "Divide and Conquer"
    },
    "greedy": {
        "class": "SolutionGreedy",
        "method": "mergeKLists",
        "complexity": "O(kN)",
        "description": "Greedy comparison"
    },
}

class SolutionHeap:
    def mergeKLists(self, lists):
        # Heap implementation
        pass

class SolutionDivideConquer:
    def mergeKLists(self, lists):
        # Divide & Conquer implementation
        pass

class SolutionGreedy:
    def mergeKLists(self, lists):
        # Greedy implementation
        pass

def solve():
    # ... parse input ...
    solver = get_solver(SOLUTIONS)
    result = solver.mergeKLists(lists)
    print(result)
```

**Run commands:**

```bash
# Run specific solution
python runner/test_runner.py 0023_merge_k_sorted_lists --method heap

# Compare all solutions
python runner/test_runner.py 0023_merge_k_sorted_lists --all --benchmark
```

**Output:**

```
============================================================
ğŸ“Š Performance Comparison
============================================================
Method               Avg Time     Complexity      Pass Rate
------------------------------------------------------------
heap                    44.36ms   O(N log k)      3/3
divide                  44.48ms   O(N log k)      3/3
greedy                  44.82ms   O(kN)           3/3
============================================================
```

Create with template: `scripts\new_problem.bat 0023_merge_k_lists --multi`

> ğŸ“– See [`docs/SOLUTION_CONTRACT.md` Â§B](docs/SOLUTION_CONTRACT.md#b-solutions-metadata-schema) for complete SOLUTIONS schema and validation rules.

### ğŸ”€ Flexible Output Validation

For problems with multiple valid answers ("return in any order"):

**Validation Modes:**

| Mode | Description | Requires `.out` |
|:-----|:------------|:---------------:|
| `[judge]` | Custom validation with reference | âœ… |
| `[judge-only]` | Custom validation only | âŒ |
| `[exact]` | Exact string match | âœ… |
| `[sorted]` | Sort before comparison | âœ… |
| `[set]` | Set comparison | âœ… |

**JUDGE_FUNC (Recommended):**

```python
def judge(actual: list, expected, input_data: str) -> bool:
    """Validate N-Queens solution."""
    n = int(input_data.strip())
    
    # Validate each board
    for board in actual:
        if not is_valid_n_queens(board, n):
            return False
    
    # Check count if expected exists
    if expected is not None:
        return len(actual) == len(expected)
    
    return True

JUDGE_FUNC = judge
```

**COMPARE_MODE (Simple Cases):**

```python
COMPARE_MODE = "sorted"  # Options: "exact" | "sorted" | "set"
```

> ğŸ“– See [`docs/SOLUTION_CONTRACT.md` Â§C](docs/SOLUTION_CONTRACT.md#c-judge--validation-contract) for complete JUDGE_FUNC signature and validation rules.

### ğŸ² Random Test Generation

Create a generator file with the same name as your solution:

```python
# generators/0004_median_of_two_sorted_arrays.py
import random
from typing import Iterator, Optional

def generate(count: int = 10, seed: Optional[int] = None) -> Iterator[str]:
    """Generate random test cases."""
    if seed is not None:
        random.seed(seed)
    
    # Edge cases first
    yield "[]\n[1]"
    yield "[1]\n[]"
    
    # Random cases
    for _ in range(count - 2):
        m = random.randint(0, 1000)
        n = random.randint(0, 1000)
        nums1 = sorted(random.randint(-10**6, 10**6) for _ in range(m))
        nums2 = sorted(random.randint(-10**6, 10**6) for _ in range(n))
        yield f"{list(nums1)}\n{list(nums2)}".replace(' ', '')
```

**Usage:**

```bash
# Run static + generated tests
python runner/test_runner.py 0004_median --generate 10

# Only generated tests
python runner/test_runner.py 0004_median --generate-only 100

# Reproducible with seed
python runner/test_runner.py 0004_median --generate 10 --seed 42

# Save failing cases
python runner/test_runner.py 0004_median --generate 10 --save-failed
```

> ğŸ“– See [`docs/GENERATOR_CONTRACT.md`](docs/GENERATOR_CONTRACT.md) for complete generator specification and best practices.

### ğŸ“ˆ Time Complexity Estimation

Add a complexity generator function:

```python
# generators/0004_median_of_two_sorted_arrays.py

def generate_for_complexity(n: int) -> str:
    """Generate test case with specific size n."""
    m = random.randint(0, n)
    return _generate_case(m, n - m)
```

**Run estimation:**

```bash
python runner/test_runner.py 0004_median --estimate
```

**Output:**

```
ğŸ“ˆ Running complexity estimation...
   Sizes: [10, 20, 50, 100, 200, 500, 1000, 2000]
   n=   10: 0.0040ms
   n=  100: 0.0082ms
   n= 1000: 0.0685ms
   n= 2000: 0.1796ms

âœ… Estimated: O(n log n)
   Confidence: 1.00
```

---

## ğŸ“ Project Architecture

```
neetcode/
â”‚
â”œâ”€â”€ solutions/                 # ğŸ“ Your solution files
â”‚   â””â”€â”€ 0001_two_sum.py
â”‚
â”œâ”€â”€ tests/                     # ğŸ“‹ Test cases
â”‚   â”œâ”€â”€ 0001_two_sum_1.in      # Input file
â”‚   â”œâ”€â”€ 0001_two_sum_1.out     # Expected output
â”‚   â””â”€â”€ *_failed_*.in          # Auto-saved failed cases (--save-failed)
â”‚
â”œâ”€â”€ generators/                # ğŸ² Random test generators (optional)
â”‚   â””â”€â”€ 0001_two_sum.py        # generate(count, seed) function
â”‚
â”œâ”€â”€ runner/                    # âš™ï¸ Test execution engine
â”‚   â”œâ”€â”€ test_runner.py         # CLI entry point & main orchestration
â”‚   â”œâ”€â”€ case_runner.py         # Single case runner (for debugging)
â”‚   â”œâ”€â”€ executor.py            # Test case execution (subprocess)
â”‚   â”œâ”€â”€ compare.py             # Output comparison (exact/sorted/set/judge)
â”‚   â”œâ”€â”€ reporter.py            # Result formatting & benchmark display
â”‚   â”œâ”€â”€ module_loader.py       # Dynamic module loading
â”‚   â”œâ”€â”€ complexity_estimator.py # Time complexity estimation (big_O)
â”‚   â”œâ”€â”€ paths.py               # Path utilities
â”‚   â”œâ”€â”€ io_utils.py            # File I/O operations
â”‚   â””â”€â”€ util.py                # Re-exports (backward compatible)
â”‚
â”œâ”€â”€ templates/                 # ğŸ“„ Problem templates
â”‚   â”œâ”€â”€ template_solution.py       # Single solution template
â”‚   â”œâ”€â”€ template_solution_multi.py # Multi-solution (polymorphic)
â”‚   â””â”€â”€ template_test.txt          # Test case template
â”‚
â”œâ”€â”€ .vscode/                   # ğŸ”§ VS Code integration
â”‚   â”œâ”€â”€ settings.json          # Python environment settings
â”‚   â”œâ”€â”€ tasks.json             # Ctrl+Shift+B shortcuts
â”‚   â””â”€â”€ launch.json            # F5 debug configurations
â”‚
â”œâ”€â”€ docs/                      # ğŸ“š Documentation (MkDocs)
â”‚   â”œâ”€â”€ index.md               # Homepage (English)
â”‚   â”œâ”€â”€ index_zh-TW.md         # Homepage (ç¹é«”ä¸­æ–‡)
â”‚   â”œâ”€â”€ mindmaps/              # Generated mind map markdown
â”‚   â”œâ”€â”€ patterns/              # Generated pattern documentation
â”‚   â”œâ”€â”€ pages/                 # Generated HTML (gitignored)
â”‚   â””â”€â”€ stylesheets/           # Custom CSS
â”‚
â”œâ”€â”€ tools/                     # ğŸ› ï¸ Utility scripts
â”‚   â”œâ”€â”€ generate_mindmaps_ai.py    # ğŸ¤– AI mind map generator
â”‚   â”œâ”€â”€ mindmap_ai_config.toml     # AI generation configuration
â”‚   â”œâ”€â”€ generate_mindmaps.py       # Rule-based mind map generator
â”‚   â”œâ”€â”€ generate_mindmaps.toml     # Rule-based configuration
â”‚   â”œâ”€â”€ generate_pattern_docs.py   # Generate pattern docs
â”‚   â”œâ”€â”€ generate_pattern_docs.toml # Pattern docs configuration
â”‚   â”œâ”€â”€ check_solutions.py         # Solution validation tool
â”‚   â”œâ”€â”€ prepare_llm_input.py       # Prepare LLM input data
â”‚   â”œâ”€â”€ text_to_mindmap.py         # Convert text to mindmap
â”‚   â”œâ”€â”€ mindmaps/                  # Mind map generator modules
â”‚   â”œâ”€â”€ patterndocs/               # Pattern docs generator modules
â”‚   â”œâ”€â”€ shared/                    # Shared utilities
â”‚   â”œâ”€â”€ prompts/                   # AI prompt management
â”‚   â”‚   â”œâ”€â”€ README.md              # Prompt documentation
â”‚   â”‚   â””â”€â”€ generated/             # Auto-generated prompts
â”‚   â””â”€â”€ tests/                     # Format validation tests
â”‚
â”œâ”€â”€ ontology/                  # ğŸ§¬ Algorithm ontology (TOML)
â”‚   â”œâ”€â”€ api_kernels.toml       # API kernel definitions
â”‚   â”œâ”€â”€ patterns.toml          # Pattern definitions
â”‚   â”œâ”€â”€ algorithms.toml        # Algorithm definitions
â”‚   â”œâ”€â”€ data_structures.toml   # Data structure definitions
â”‚   â”œâ”€â”€ companies.toml         # Company definitions
â”‚   â”œâ”€â”€ topics.toml            # Topic definitions
â”‚   â”œâ”€â”€ difficulties.toml      # Difficulty levels
â”‚   â”œâ”€â”€ families.toml          # Problem family definitions
â”‚   â””â”€â”€ roadmaps.toml          # Roadmap definitions
â”‚
â”œâ”€â”€ meta/                      # ğŸ“Š Problem & pattern metadata
â”‚   â”œâ”€â”€ problems/              # Problem metadata (one TOML per problem)
â”‚   â”‚   â””â”€â”€ *.toml
â”‚   â””â”€â”€ patterns/              # Pattern documentation sources
â”‚       â””â”€â”€ <pattern_name>/    # Pattern-specific markdown
â”‚
â”œâ”€â”€ roadmaps/                  # ğŸ—ºï¸ Learning path definitions
â”‚   â”œâ”€â”€ neetcode_150.toml
â”‚   â”œâ”€â”€ blind_75.toml
â”‚   â””â”€â”€ sliding_window_path.toml
â”‚
â”œâ”€â”€ .dev/                      # ğŸ§ª Maintainer zone (unit tests)
â”‚   â”œâ”€â”€ tests/                 # Unit test suite (150+ cases)
â”‚   â”œâ”€â”€ tests_solutions/       # Solution validation tests
â”‚   â”œâ”€â”€ scripts/run_tests.bat/.sh  # Run runner unit tests
â”‚   â”œâ”€â”€ run_all_tests.bat/.sh  # Run all unit tests
â”‚   â”œâ”€â”€ run_tests_solutions.bat/.sh  # Run solution tests
â”‚   â”œâ”€â”€ TESTING.md             # Testing documentation
â”‚   â”œâ”€â”€ VIRTUAL_ENV_SETUP.md   # Virtual environment guide
â”‚   â””â”€â”€ README.md              # Maintainer guide
â”‚
â”œâ”€â”€ .github/                   # ğŸš€ GitHub configuration
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-pages.yml   # GitHub Pages deployment
â”‚
â”œâ”€â”€ leetcode/                  # ğŸ Python virtual environment (3.11)
â”‚
â”œâ”€â”€ scripts/                   # ğŸ”§ Utility scripts
â”‚   â”œâ”€â”€ new_problem.bat / .sh  # Create new problem from template
â”‚   â”œâ”€â”€ run_tests.bat / .sh    # Run all tests for a problem
â”‚   â”œâ”€â”€ run_case.bat / .sh     # Run single test case
â”‚   â””â”€â”€ build_docs.bat / .sh   # Build documentation site
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ mkdocs.yml                 # MkDocs configuration
â”œâ”€â”€ pytest.ini                 # pytest configuration
â”œâ”€â”€ README.md                  # This file (English)
â””â”€â”€ README_zh-TW.md            # ç¹é«”ä¸­æ–‡ç‰ˆ
```

### Directory Guide

| Directory | Purpose | Target Audience |
|:----------|:--------|:----------------|
| `solutions/` | Write your solutions here | âœ… All users |
| `tests/` | Add test cases (.in/.out) | âœ… All users |
| `generators/` | Random test generators | âœ… All users |
| `runner/` | Test execution engine | ğŸ”§ Contributors |
| `templates/` | Problem templates | âœ… All users |
| `.vscode/` | VS Code configuration | âœ… All users |
| `docs/` | MkDocs documentation | ğŸ”§ Contributors |
| `tools/` | Documentation generators | ğŸ”§ Contributors |
| `ontology/` | Algorithm ontology data | ğŸ”§ Contributors |
| `meta/` | Problem/pattern metadata | ğŸ”§ Contributors |
| `.dev/` | Unit tests (150+ cases) | ğŸ”§ Maintainers |

> **ğŸ“ Note:** Files in `docs/mindmaps/`, `docs/patterns/`, and `docs/pages/` are auto-generated. Edit the source files in `ontology/`, `meta/`, and `tools/` instead.

### Documentation Guide

Documentation is organized by **target audience**:

| Location | Purpose | Audience |
|:---------|:--------|:---------|
| `docs/` | User documentation (published to website) | âœ… Users |
| `tools/README.md` | Developer tools reference | ğŸ”§ Contributors |
| `tools/*/README.md` | Module technical details | ğŸ”§ Contributors |
| `.dev/` | Maintainer documentation | ğŸ”§ Maintainers |

**Key Documentation Files:**

| Document | Description |
|:---------|:------------|
| [`docs/SOLUTION_CONTRACT.md`](docs/SOLUTION_CONTRACT.md) | Solution file specification |
| [`docs/GENERATOR_CONTRACT.md`](docs/GENERATOR_CONTRACT.md) | Generator file specification |
| [`tools/README.md`](tools/README.md) | Complete tools reference |
| [`.dev/README.md`](.dev/README.md) | Maintainer guide |
| [`.dev/DOCUMENTATION_ARCHITECTURE.md`](.dev/DOCUMENTATION_ARCHITECTURE.md) | Documentation structure |

---

## â“ Frequently Asked Questions

<details>
<summary><strong>What problems does this framework solve?</strong></summary>

- Running multiple algorithm implementations automatically
- Generating reproducible random test data for stress testing
- Benchmarking solutions to identify performance differences
- Debugging LeetCode-style problems with VS Code integration
- Validating outputs using custom logic beyond simple file comparison

</details>

<details>
<summary><strong>How is this different from copying LeetCode solutions?</strong></summary>

This is not a solution collection â€” it's a **testing infrastructure**. You write solutions, and the framework:

1. Runs them against static test cases
2. Generates random test cases automatically
3. Validates correctness using custom judge functions
4. Benchmarks multiple solutions against each other
5. Estimates time complexity empirically

</details>

<details>
<summary><strong>Can I use this for interview preparation?</strong></summary>

Absolutely! The framework is perfect for interview prep:

- Practice writing solutions in **real LeetCode format**
- Find **edge cases you might miss** with random test generation
- See which approach is **actually faster** with benchmarking
- **Debug easily** with VS Code integration

</details>

<details>
<summary><strong>What Python version is required?</strong></summary>

Python 3.11 â€” matching the [LeetCode official environment](https://support.leetcode.com/hc/en-us/articles/360011833974-What-are-the-environments-for-the-programming-languages).

</details>

---

## ğŸ› ï¸ For Contributors

### Running Unit Tests

```bash
# Activate virtual environment
leetcode\Scripts\activate  # Windows
source leetcode/bin/activate  # Linux/macOS

# Run all tests
python -m pytest .dev/tests -v

# With coverage
python -m pytest .dev/tests --cov=runner --cov-report=html
```

### Generate Mind Maps Locally

**AI-Powered (Recommended):**

```bash
# Interactive mode
python tools/generate_mindmaps_ai.py

# With specific goal
python tools/generate_mindmaps_ai.py --goal interview

# Generate multiple languages
# Edit tools/mindmap_ai_config.toml: language = ["en", "zh-TW"]
python tools/generate_mindmaps_ai.py
```

Configuration: `tools/mindmap_ai_config.toml`

**Rule-Based:**

```bash
# Generate Markdown mind maps
python tools/generate_mindmaps.py

# Generate HTML (interactive) mind maps
python tools/generate_mindmaps.py --html
```

Configuration: `tools/generate_mindmaps.toml`

### Documentation

- [`.dev/README.md`](https://github.com/lufftw/neetcode/blob/main/.dev/README.md) â€” Maintainer guide
- [`.dev/TESTING.md`](https://github.com/lufftw/neetcode/blob/main/.dev/TESTING.md) â€” Testing documentation
- [`docs/SOLUTION_CONTRACT.md`](docs/SOLUTION_CONTRACT.md) â€” Solution file specification (SOLUTIONS dict, JUDGE_FUNC)
- [`docs/GENERATOR_CONTRACT.md`](docs/GENERATOR_CONTRACT.md) â€” Generator file specification (generate(), edge cases, complexity)
- [`docs/ARCHITECTURE_MIGRATION.md`](docs/ARCHITECTURE_MIGRATION.md) â€” Polymorphic architecture migration guide
- [`docs/GITHUB_PAGES_SETUP.md`](docs/GITHUB_PAGES_SETUP.md) â€” Deployment guide

---

## ğŸ“œ License

**MIT License** â€” Free for personal learning and educational use.

---

**Built with â¤ï¸ for the competitive programming community**
