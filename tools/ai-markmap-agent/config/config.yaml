# =============================================================================
# AI Markmap Agent Configuration
# =============================================================================
# All parameters are configurable: models, prompts, agent counts, rounds, etc.
# =============================================================================

# -----------------------------------------------------------------------------
# Prompt Mode Configuration
# -----------------------------------------------------------------------------
# Choose between static (pre-defined) prompts or dynamic (AI-generated) prompts
prompt_mode:
  # "static" = Use pre-defined prompts in prompts/ directory
  # "dynamic" = Generate prompts using AI at runtime
  mode: "static"
  
  # Model to use for generating dynamic prompts (only used when mode="dynamic")
  generator_model: "gpt-5"
  
  # Meta-prompts for dynamic generation
  meta_prompts:
    persona_generator: "prompts/meta/generate_optimizer_persona.md"
    behavior_generator: "prompts/meta/generate_optimizer_behavior.md"
    role_suggester: "prompts/meta/suggest_optimizer_roles.md"
  
  # Cache generated prompts (recommended for consistency across runs)
  cache_generated: true
  cache_dir: "prompts/generated"

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
models:
  # Generalist - Broad understanding, knowledge organization
  generalist:
    en:
      model: "gpt-5"
      persona_prompt: "prompts/generators/generalist_persona.md"
      behavior_prompt: "prompts/generators/generalist_behavior.md"
      temperature: 0.7
      max_tokens: 4096
    zh:
      model: "gpt-5"
      persona_prompt: "prompts/generators/generalist_persona.md"
      behavior_prompt: "prompts/generators/generalist_behavior.md"
      temperature: 0.7
      max_tokens: 4096

  # Specialist - Engineering details, structural rigor
  specialist:
    en:
      model: "gpt-5"
      persona_prompt: "prompts/generators/specialist_persona.md"
      behavior_prompt: "prompts/generators/specialist_behavior.md"
      temperature: 0.5
      max_tokens: 4096
    zh:
      model: "gpt-5"
      persona_prompt: "prompts/generators/specialist_persona.md"
      behavior_prompt: "prompts/generators/specialist_behavior.md"
      temperature: 0.5
      max_tokens: 4096

  # Optimizers - Three distinct expert perspectives for debate
  optimizer:
    # Top-tier Software Architect (Dr. Alexander Chen)
    - id: "optimizer_architect"
      name: "The Software Architect"
      persona_name: "Dr. Alexander Chen"
      model: "gpt-5"
      persona_prompt: "prompts/optimizers/optimizer_architect_persona.md"
      behavior_prompt: "prompts/optimizers/optimizer_architect_behavior.md"
      temperature: 0.6
      max_tokens: 4096
      focus: "architecture_modularity"
      # For dynamic mode:
      dynamic_config:
        role_description: "Top-tier Software Architect"
        focus_area: "system design, modularity, clean architecture, design patterns"
        perspective: "structural and organizational excellence"
    
    # Senior Algorithm Professor (Prof. David Knuth Jr.)
    - id: "optimizer_professor"
      name: "The Algorithm Professor"
      persona_name: "Prof. David Knuth Jr."
      model: "gpt-5.1"
      persona_prompt: "prompts/optimizers/optimizer_professor_persona.md"
      behavior_prompt: "prompts/optimizers/optimizer_professor_behavior.md"
      temperature: 0.6
      max_tokens: 4096
      focus: "correctness_completeness"
      # For dynamic mode:
      dynamic_config:
        role_description: "Distinguished Algorithm Professor and Computer Scientist"
        focus_area: "algorithms, data structures, computational complexity, formal methods"
        perspective: "academic rigor and correctness"
    
    # Senior Technical Architect / API Designer (James Patterson)
    - id: "optimizer_apidesigner"
      name: "The Technical API Architect"
      persona_name: "James Patterson"
      model: "gpt-5.2"
      persona_prompt: "prompts/optimizers/optimizer_apidesigner_persona.md"
      behavior_prompt: "prompts/optimizers/optimizer_apidesigner_behavior.md"
      temperature: 0.7
      max_tokens: 4096
      focus: "developer_experience"
      # For dynamic mode:
      dynamic_config:
        role_description: "Senior Technical Architect and API Designer"
        focus_area: "API design, developer experience, documentation, interface patterns"
        perspective: "usability and developer-centric design"

  # Summarizer - Consolidates each round's discussion
  summarizer:
    model: "gpt-5.2"
    persona_prompt: "prompts/summarizer/summarizer_persona.md"
    behavior_prompt: "prompts/summarizer/summarizer_behavior.md"
    temperature: 0.5
    max_tokens: 4096

  # Judges - Final evaluation and selection
  judges:
    - id: "judge_quality"
      name: "Quality Judge"
      model: "gpt-4"
      persona_prompt: "prompts/judges/judge_quality_persona.md"
      behavior_prompt: "prompts/judges/judge_quality_behavior.md"
      temperature: 0.4
      max_tokens: 4096
      criteria:
        - "structure_quality"
        - "naming_consistency"
        - "technical_accuracy"
    
    - id: "judge_completeness"
      name: "Completeness Judge"
      model: "gpt-4"
      persona_prompt: "prompts/judges/judge_completeness_persona.md"
      behavior_prompt: "prompts/judges/judge_completeness_behavior.md"
      temperature: 0.4
      max_tokens: 4096
      criteria:
        - "knowledge_coverage"
        - "practical_value"
        - "depth_balance"

  # Compressor - For summarizing long content (use cheaper model)
  compressor:
    model: "gpt-3.5-turbo"
    behavior_prompt: "prompts/compressor/compressor_behavior.md"
    temperature: 0.3
    max_tokens: 2048

# -----------------------------------------------------------------------------
# Workflow Configuration
# -----------------------------------------------------------------------------
workflow:
  # Number of optimization rounds
  optimization_rounds: 3
  
  # Number of optimizers (must match models.optimizer count)
  optimizer_count: 3
  
  # Number of judges (must match models.judges count)
  judge_count: 2
  
  # Token threshold to trigger compression
  max_tokens_before_compress: 8000
  
  # Enable parallel baseline generation (Phase 1)
  parallel_baseline_generation: true
  
  # Enable debate between judges
  enable_debate: true
  
  # Maximum debate rounds
  max_debate_rounds: 2

# -----------------------------------------------------------------------------
# Memory Configuration
# -----------------------------------------------------------------------------
memory:
  stm:
    enabled: true
    max_items: 50
  
  ltm:
    enabled: true
    vector_store: "chromadb"
    collection_name: "markmap_decisions"
    embedding_model: "text-embedding-3-small"
    chromadb:
      persist_directory: "./data/chromadb"
    retrieval:
      k: 5
      score_threshold: 0.7

# -----------------------------------------------------------------------------
# Output Configuration
# -----------------------------------------------------------------------------
output:
  save_intermediate: true
  intermediate_dir: "outputs/intermediate"
  final_dir: "outputs/final"
  naming:
    baseline: "markmap_{type}_{lang}.md"
    round: "markmap_round_{n}.md"
    final_md: "markmap_final.md"
    final_html: "markmap_final.html"
  html:
    template: "templates/markmap.html"
    include_styles: true
    include_scripts: true
    title: "AI Generated Markmap"

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------
api:
  openai:
    api_key: "${OPENAI_API_KEY}"
    organization: "${OPENAI_ORG_ID}"
    base_url: null
  retry:
    max_retries: 3
    retry_delay: 1.0
    exponential_backoff: true

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/ai_markmap_agent.log"
  console: true
  log_llm_calls: false

# -----------------------------------------------------------------------------
# Development Configuration
# -----------------------------------------------------------------------------
dev:
  debug: false
  use_mock_llm: false
  langgraph_studio:
    enabled: true
    port: 8123
